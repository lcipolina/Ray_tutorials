{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzcF06Hlsmv6dYc1TLy5h7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/Ray_tutorials/blob/main/RLLIB_MARL_Empty_action_Ray_2_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example creates a simple multi-agent custom environment and trains it using Tune and Air.\n",
        "\n",
        "Its aim is to investigate the generation of empty action_dictionaries coming from RLLIB's policy."
      ],
      "metadata": {
        "id": "UNUx3s0gLBHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[rllib]==2.2.0 --quiet"
      ],
      "metadata": {
        "id": "QGQE1Tje5vN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' FOR NEWER RLLIB ONLY\n",
        "!pip install gymnasium --quiet\n",
        "import gymnasium as gym\n",
        "'''"
      ],
      "metadata": {
        "id": "gL1UJd4vLuVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1f0576e0-9a9e-4efe-b73d-8cb4d9ed9ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' FOR NEWER RLLIB ONLY\\n!pip install gymnasium --quiet\\nimport gymnasium as gym\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import ray\n",
        "from ray.rllib.env import MultiAgentEnv\n",
        "from gym.spaces import MultiDiscrete\n",
        "from ray import air, tune\n",
        "from gym.spaces import Tuple, Box, MultiDiscrete, Discrete\n",
        "from ray.rllib.algorithms.ppo import PPOConfig"
      ],
      "metadata": {
        "id": "xu8STO3wkm20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d927f3-7b41-4024-dcc0-7be7c19561e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/rpc/__init__.py:20: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.rpc')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  pkg_resources.declare_namespace(__name__)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(parent)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG62SSDSK50i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5a6289-13d4-49da-819c-bc8f1e201674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Simple MARL custom Environment\n",
        "\n",
        "'''Simple Multi-agent environment to test things\n",
        "'''\n",
        "\n",
        "\n",
        "class TurnEnv(MultiAgentEnv):\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        super().__init__()\n",
        "        self.num_agents              = 2\n",
        "        self.t                       = 0\n",
        "        self.agent_lst               = list(range(self.num_agents))\n",
        "        self._agent_ids              = set(self.agent_lst)\n",
        "        self.dones_dict              = {agent: False for agent in self.agent_lst}\n",
        "        self.dones_dict['__all__']   = False\n",
        "        self.observation_space       = Discrete(self.num_agents)\n",
        "        self.action_space            = self.observation_space\n",
        "\n",
        "    def reset(self):\n",
        "        return {0: self.observation_space.sample()}  # {agent:obs}\n",
        "\n",
        "\n",
        "    def step(self, action_dict):\n",
        "        \n",
        "        self.t +=1\n",
        "        \n",
        "     \n",
        "        if not action_dict:\n",
        "           print(\"EMPTY ACTION DICT!!!\")\n",
        "           print('self.t =', self.t)\n",
        "       \n",
        "        if self.t == 10: \n",
        "           self.dones_dict              = {agent: True for agent in self.agent_lst}\n",
        "           self.dones_dict['__all__']   = True\n",
        "\n",
        "        return {1:self.observation_space.sample()},\\\n",
        "               {1:1},\\\n",
        "               self.dones_dict, \\\n",
        "               {} #{agent:obs}, {agent:rews}, dones, info\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure experiments and train"
      ],
      "metadata": {
        "id": "PDAtJb0lkIC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ray():\n",
        "\n",
        "    #Register custom env\n",
        "    env_name = 'TurnEnv'\n",
        "    tune.register_env(env_name, lambda env_ctx: TurnEnv()) #the register_env needs a callable/iterable\n",
        "\n",
        "    #Experiment configuration\n",
        "    NUM_CPUS = os.cpu_count()\n",
        "\n",
        "    config = PPOConfig()\\\n",
        "    .framework(\"torch\")\\\n",
        "    .rollouts(num_rollout_workers=1, observation_filter=\"MeanStdFilter\")\\\n",
        "    .resources(num_gpus=0,num_cpus_per_worker=1)\\\n",
        "    .evaluation(evaluation_interval=2,evaluation_duration = 2, evaluation_duration_unit='episodes',\n",
        "                evaluation_config= {\"explore\": False})\\\n",
        "    .environment(env = TurnEnv, env_config={\n",
        "                                     \"num_workers\": NUM_CPUS - 1,\n",
        "                                     \"disable_env_checking\":True} \n",
        "\n",
        "                )\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "    train_steps = 1\n",
        "    experiment_name = 'my_experiment'\n",
        "    tuner = tune.Tuner(\"PPO\", param_space=config,\n",
        "                              run_config=air.RunConfig(\n",
        "                                        name =  experiment_name,\n",
        "                                        stop={\"timesteps_total\": train_steps},\n",
        "                                        checkpoint_config=air.CheckpointConfig(checkpoint_frequency=1, checkpoint_at_end=True),\n",
        "                                        verbose= 0\n",
        "                                )\n",
        "                     )\n",
        "    results = tuner.fit()\n",
        "\n",
        "    #check_learning_achieved(results, stop_reward)\n",
        "    df = results.get_dataframe()\n",
        "    best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
        "    #print(best_result)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "2K8gAQtWkGF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ray.is_initialized(): ray.shutdown()\n",
        "ray.init(local_mode=True,include_dashboard=False, ignore_reinit_error=True) \n",
        "\n",
        "train_ray()\n",
        "\n",
        "ray.shutdown()\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "-_nXvDaxkbx9",
        "outputId": "8bab2ab8-3ec3-4ab4-fe27-616df99c0330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-01 17:09:29,460\tWARNING worker.py:837 -- `ray.get_gpu_ids()` will always return the empty list when called from the driver. This is because Ray does not manage GPU allocations to the driver process.\n",
            ":task_name:bundle_reservation_check_func\n",
            ":actor_name:PPO\n",
            "2023-05-01 17:09:29,617\tWARNING algorithm_config.py:488 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
            "2023-05-01 17:09:29,631\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":task_name:bundle_reservation_check_func\n",
            ":actor_name:PPO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ":actor_name:RolloutWorker\n",
            "2023-05-01 17:09:29,792\tWARNING multi_agent_env.py:266 -- observation_space_sample() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,794\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,800\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,807\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,813\tWARNING multi_agent_env.py:228 -- action_space_sample() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,831\tWARNING multi_agent_env.py:190 -- action_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/pre_checks/env.py:434: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if not isinstance(done_, (bool, np.bool, np.bool_)):\n",
            "2023-05-01 17:09:29,840\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,931\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,934\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,946\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,954\tWARNING multi_agent_env.py:228 -- action_space_sample() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/pre_checks/env.py:434: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if not isinstance(done_, (bool, np.bool, np.bool_)):\n",
            "2023-05-01 17:09:29,956\tWARNING multi_agent_env.py:160 -- observation_space_contains() of <TurnEnv instance> has not been implemented. You can either implement it yourself or bring the observation space into the preferred format of a mapping from agent ids to their individual observation spaces. \n",
            "2023-05-01 17:09:29,984\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":actor_name:RolloutWorker\n",
            "EMPTY ACTION DICT!!!\n",
            "self.t = 1\n",
            "EMPTY ACTION DICT!!!\n",
            "self.t = 1\n",
            ":actor_name:PPO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ":actor_name:PPO\n",
            "/usr/local/lib/python3.10/dist-packages/ray/rllib/utils/filter.py:84: DeprecationWarning: Passing None into shape arguments as an alias for () is deprecated.\n",
            "  self.mean_array = np.zeros(shape)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    }
  ]
}