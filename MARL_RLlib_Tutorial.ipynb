{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/Ray/blob/main/MARL_RLlib_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_IXCSrDJacm"
      },
      "source": [
        "# Hands-on RL with Ray’s RLlib \n",
        "<hr />\n",
        "\n",
        "Taken from here:\n",
        "https://risecamp.berkeley.edu/archives/rise-camp-2021/\n",
        "\n",
        "Also here:\n",
        "https://github.com/sven1977/rllib_tutorials\n",
        "\n",
        "## Tutorial for working with multi-agent environments, models, and algorithms\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1s1chO-ET7inBCKDdKgP4hI0UgTI4bLPs\" width=250> <img src=\"https://drive.google.com/uc?export=view&id=1GGD7V_oO1osZqgKF8QzajM3_bs5o9fNw\" width=169> <img src=\"https://drive.google.com/uc?export=view&id=1xJTlXqv182zVvDPeRc2lEg06zU0GbNrK\" width=252> <img src=\"https://drive.google.com/uc?export=view&id=1X3eVsp3hhFzwFaeqOwwZ9DmJ0UiYfu4y\" width=213>\n",
        "\n",
        "### Overview\n",
        "“Hands-on RL with Ray’s RLlib” is a beginners tutorial for working with reinforcement learning (RL) environments, models, and algorithms using Ray’s RLlib library. RLlib offers high scalability, a large list of algos to choose from (offline, model-based, model-free, etc..), support for TensorFlow and PyTorch, and a unified API for a variety of applications. This tutorial includes a brief introduction to provide an overview of concepts (e.g. why RL) before proceeding to RLlib (multi- and single-agent) environments, neural network models, student exercises, Q/A, and more. All code will be provided as .py files in a GitHub repo.\n",
        "\n",
        "### Intended Audience\n",
        "* Python programmers who want to get started with reinforcement learning and RLlib.\n",
        "\n",
        "### Prerequisites\n",
        "* Some Python programming experience.\n",
        "* Some familiarity with machine learning.\n",
        "* *Helpful, but not required:* Experience in reinforcement learning and Ray.\n",
        "* *Helpful, but not required:* Experience with TensorFlow or PyTorch.\n",
        "\n",
        "### Requirements/Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l93OCdB-JZHF"
      },
      "outputs": [],
      "source": [
        "!pip install ray[rllib]\n",
        "!pip install tensorflow -U  # <- either one works!\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyoT5cyVKYa_"
      },
      "source": [
        "### Key Takeaways\n",
        "* What is reinforcement learning and why RLlib?\n",
        "* Core concepts of RLlib: Environments, Trainers, Policies, and Models.\n",
        "\n",
        "### Tutorial Outline (30-40 min)\n",
        "1. RL and RLlib in a nutshell.\n",
        "1. Defining an RL-solvable problem: Our first (multi-agent) environment.\n",
        "1. **Exercise No.1**: Environment Loop.\n",
        "1. Picking an algorithm and training our first RLlib Trainer.\n",
        "1. **Exercise No.2** Fixing our experiment's config - Going multi-agent.\n",
        "\n",
        "### Other Recommended Readings\n",
        "* [Reinforcement Learning with RLlib in the Unity Game Engine](https://medium.com/distributed-computing-with-ray/reinforcement-learning-with-rllib-in-the-unity-game-engine-1a98080a7c0d)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mgu5vPHwTB-3uch1d43BICQoK0h9XkbO\" width=400>\n",
        "\n",
        "* [Attention Nets and More with RLlib's Trajectory View API](https://medium.com/distributed-computing-with-ray/attention-nets-and-more-with-rllibs-trajectory-view-api-d326339a6e65)\n",
        "* [Intro to RLlib: Example Environments](https://medium.com/distributed-computing-with-ray/intro-to-rllib-example-environments-3a113f532c70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_44DB84Sgwd"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "### Coding/defining our \"problem\" via an RL environment.\n",
        "\n",
        "We will use the following (adversarial) multi-agent environment\n",
        "throughout this tutorial to demonstrate RLlib's\n",
        "APIs, features, and customization options.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1GL5LDrrnw0rx-cYK9ucQ4drpaykz1pBd\" width=800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wlIyZPBTWgf"
      },
      "source": [
        "### A word or two on Spaces:\n",
        "\n",
        "Spaces are used in ML to describe what possible/valid values inputs and outputs of a neural network can have.\n",
        "\n",
        "RL environments also use them to describe what their valid observations and actions are.\n",
        "\n",
        "Spaces are usually defined by their shape (e.g. 84x84x3 RGB images) and datatype (e.g. uint8 for RGB values between 0 and 255).\n",
        "However, spaces could also be composed of other spaces (see Tuple or Dict spaces) or could be simply discrete with n fixed possible values\n",
        "(represented by integers). For example, in our game, where each agent can only go up/down/left/right, the action space would be `Discrete(4)`\n",
        "(no datatype, no shape needs to be defined here). Our observation space will be `MultiDiscrete([n, m])`, where n is the position of the agent observing and m is the position of the opposing agent, so if agent1 starts in the upper left corner and agent2 starts in the bottom right corner, agent1's observation would be: `[0, 63]` (in an 8 x 8 grid) and agent2's observation would be `[63, 0]`.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zTklLKfSzK4ia054NNFMq3KLWii2QYa3\" width=800>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-SaHGPCzPa5",
        "outputId": "32467f8d-f4b7-48fd-a3ce-4b4fa952428f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________\n",
            "|.         |\n",
            "|1         |\n",
            "|          |\n",
            "|          |\n",
            "|          |\n",
            "|          |\n",
            "|          |\n",
            "|          |\n",
            "|         2|\n",
            "|          |\n",
            "‾‾‾‾‾‾‾‾‾‾‾‾\n",
            "\n",
            "R1= 1.0\n",
            "R2=-0.1\n",
            "\n",
            "Agent1's x/y position=[1, 0]\n",
            "Agent2's x/y position=[8, 9]\n",
            "Env timesteps=1\n"
          ]
        }
      ],
      "source": [
        "# Let's code our multi-agent environment.\n",
        "\n",
        "import gym\n",
        "from gym.spaces import Discrete, MultiDiscrete\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
        "\n",
        "\n",
        "class MultiAgentArena(MultiAgentEnv):\n",
        "    def __init__(self, config=None):\n",
        "        \"\"\" Config takes in width, height, and ts \"\"\"\n",
        "        config = config or {}\n",
        "        # Dimensions of the grid.\n",
        "        self.width = config.get(\"width\", 10)\n",
        "        self.height = config.get(\"height\", 10)\n",
        "\n",
        "        # End an episode after this many timesteps.\n",
        "        self.timestep_limit = config.get(\"ts\", 100)\n",
        "\n",
        "        self.observation_space = MultiDiscrete([self.width * self.height,\n",
        "                                                self.width * self.height])\n",
        "        # 0=up, 1=right, 2=down, 3=left.\n",
        "        self.action_space = Discrete(4)\n",
        "\n",
        "        # Reset env.\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        \"\"\"Returns initial observation of next(!) episode.\"\"\"\n",
        "        # Row-major coords.\n",
        "        self.agent1_pos = [0, 0]  # upper left corner\n",
        "        self.agent2_pos = [self.height - 1, self.width - 1]  # lower bottom corner\n",
        "\n",
        "        # Accumulated rewards in this episode.\n",
        "        self.agent1_R = 0.0\n",
        "        self.agent2_R = 0.0\n",
        "\n",
        "        # Reset agent1's visited fields.\n",
        "        self.agent1_visited_fields = set([tuple(self.agent1_pos)])\n",
        "\n",
        "        # How many timesteps have we done in this episode.\n",
        "        self.timesteps = 0\n",
        "\n",
        "        # Return the initial observation in the new episode.\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action: dict):\n",
        "        \"\"\"\n",
        "        Returns (next observation, rewards, dones, infos) after having taken the given actions.\n",
        "        \n",
        "        e.g.\n",
        "        `action={\"agent1\": action_for_agent1, \"agent2\": action_for_agent2}`\n",
        "        \"\"\"\n",
        "        \n",
        "        # increase our time steps counter by 1.\n",
        "        self.timesteps += 1\n",
        "        # An episode is \"done\" when we reach the time step limit.\n",
        "        is_done = self.timesteps >= self.timestep_limit\n",
        "\n",
        "        # Agent2 always moves first.\n",
        "        # events = [collision|agent1_new_field]\n",
        "        events = self._move(self.agent2_pos, action[\"agent2\"], is_agent1=False)\n",
        "        events = self._move(self.agent1_pos, action[\"agent1\"], is_agent1=True)\n",
        "\n",
        "        # Useful for rendering.\n",
        "        self.collision = \"collision\" in events\n",
        "            \n",
        "        # Get observations (based on new agent positions).\n",
        "        obs = self._get_obs()\n",
        "\n",
        "        # Determine rewards based on the collected events:\n",
        "        r1 = -1.0 if \"collision\" in events else 1.0 if \"agent1_new_field\" in events else -0.5\n",
        "        r2 = 1.0 if \"collision\" in events else -0.1\n",
        "\n",
        "        self.agent1_R += r1\n",
        "        self.agent2_R += r2\n",
        "        \n",
        "        rewards = {\n",
        "            \"agent1\": r1,\n",
        "            \"agent2\": r2,\n",
        "        }\n",
        "\n",
        "        # Generate a `done` dict (per-agent and total).\n",
        "        dones = {\n",
        "            \"agent1\": is_done,\n",
        "            \"agent2\": is_done,\n",
        "            # special `__all__` key indicates that the episode is done for all agents.\n",
        "            \"__all__\": is_done,\n",
        "        }\n",
        "\n",
        "        return obs, rewards, dones, {}  # <- info dict (not needed here).\n",
        "\n",
        "    def _get_obs(self):\n",
        "        \"\"\"\n",
        "        Returns obs dict (agent name to discrete-pos tuple) using each\n",
        "        agent's current x/y-positions.\n",
        "        \"\"\"\n",
        "        ag1_discrete_pos = self.agent1_pos[0] * self.width + \\\n",
        "            (self.agent1_pos[1] % self.width)\n",
        "        ag2_discrete_pos = self.agent2_pos[0] * self.width + \\\n",
        "            (self.agent2_pos[1] % self.width)\n",
        "        return {\n",
        "            \"agent1\": np.array([ag1_discrete_pos, ag2_discrete_pos]),\n",
        "            \"agent2\": np.array([ag2_discrete_pos, ag1_discrete_pos]),\n",
        "        }\n",
        "\n",
        "    def _move(self, coords, action, is_agent1):\n",
        "        \"\"\"\n",
        "        Moves an agent (agent1 iff is_agent1=True, else agent2) from `coords` (x/y) using the\n",
        "        given action (0=up, 1=right, etc..) and returns a resulting events dict:\n",
        "        Agent1: \"new\" when entering a new field. \"bumped\" when having been bumped into by agent2.\n",
        "        Agent2: \"bumped\" when bumping into agent1 (agent1 then gets -1.0).\n",
        "        \"\"\"\n",
        "        orig_coords = coords[:]\n",
        "        # Change the row: 0=up (-1), 2=down (+1)\n",
        "        coords[0] += -1 if action == 0 else 1 if action == 2 else 0\n",
        "        # Change the column: 1=right (+1), 3=left (-1)\n",
        "        coords[1] += 1 if action == 1 else -1 if action == 3 else 0\n",
        "\n",
        "        # Solve collisions.\n",
        "        # Make sure, we don't end up on the other agent's position.\n",
        "        # If yes, don't move (we are blocked).\n",
        "        if (is_agent1 and coords == self.agent2_pos) or (not is_agent1 and coords == self.agent1_pos):\n",
        "            coords[0], coords[1] = orig_coords\n",
        "            # Agent2 blocked agent1 (agent1 tried to run into agent2)\n",
        "            # OR Agent2 bumped into agent1 (agent2 tried to run into agent1)\n",
        "            return {\"collision\"}\n",
        "\n",
        "        # No agent blocking -> check walls.\n",
        "        if coords[0] < 0:\n",
        "            coords[0] = 0\n",
        "        elif coords[0] >= self.height:\n",
        "            coords[0] = self.height - 1\n",
        "        if coords[1] < 0:\n",
        "            coords[1] = 0\n",
        "        elif coords[1] >= self.width:\n",
        "            coords[1] = self.width - 1\n",
        "\n",
        "        # If agent1 -> \"new\" if new tile covered.\n",
        "        if is_agent1 and not tuple(coords) in self.agent1_visited_fields:\n",
        "            self.agent1_visited_fields.add(tuple(coords))\n",
        "            return {\"agent1_new_field\"}\n",
        "        # No new tile for agent1.\n",
        "        return set()\n",
        "\n",
        "    def render(self, mode=None):\n",
        "        '''\n",
        "        Prints (displays) the ASCII versio of the environment\n",
        "        '''\n",
        "        print(\"_\" * (self.width + 2))\n",
        "        for r in range(self.height):\n",
        "            print(\"|\", end=\"\")\n",
        "            for c in range(self.width):\n",
        "                field = r * self.width + c % self.width\n",
        "                if self.agent1_pos == [r, c]:\n",
        "                    print(\"1\", end=\"\")\n",
        "                elif self.agent2_pos == [r, c]:\n",
        "                    print(\"2\", end=\"\")\n",
        "                elif (r, c) in self.agent1_visited_fields:\n",
        "                    print(\".\", end=\"\")\n",
        "                else:\n",
        "                    print(\" \", end=\"\")\n",
        "            print(\"|\")\n",
        "        print(\"‾\" * (self.width + 2))\n",
        "        print(f\"{'!!Collision!!' if self.collision else ''}\")\n",
        "        print(\"R1={: .1f}\".format(self.agent1_R))\n",
        "        print(\"R2={: .1f}\".format(self.agent2_R))\n",
        "        print()\n",
        "\n",
        "\n",
        "env = MultiAgentArena()\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "# Agent1 will move down, Agent2 moves up.\n",
        "obs, rewards, dones, infos = env.step(action={\"agent1\": 2, \"agent2\": 0})\n",
        "\n",
        "env.render()\n",
        "\n",
        "print(\"Agent1's x/y position={}\".format(env.agent1_pos))\n",
        "print(\"Agent2's x/y position={}\".format(env.agent2_pos))\n",
        "print(\"Env timesteps={}\".format(env.timesteps))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ler482dUPUbn"
      },
      "source": [
        "## Exercise No 1: Environment Rollout using Random Actions\n",
        "\n",
        "<hr />\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ta1s0QOfSCtuK0ZbmviwkI_6GcBWmXzY\" width=800>\n",
        "\n",
        "In the cell above, we performed a `reset()` and a single `step()` call. \n",
        "\n",
        "To walk through an entire **episode**, one would normally call `step()` repeatedly (with different actions) until the returned `done` dict has the \"agent1\" or \"agent2\" (or \"__all__\") key set to True. \n",
        "\n",
        "Your task is to write an \"environment loop\" that runs for exactly one episode using our `MultiAgentArena` class.\n",
        "\n",
        "Follow these instructions here to get this done.\n",
        "\n",
        "1. `reset` the already created (variable `env`) environment to get the first (initial) observation.\n",
        "1. Enter an infinite while loop.\n",
        "1. Compute the actions for \"agent1\" and \"agent2\" calling `DummyTrainer.compute_action([obs])` twice (once for each agent).\n",
        "1. Put the results of the action computations into an action dict (`{\"agent1\": ..., \"agent2\": ...}`).\n",
        "1. Pass this action dict into the env's `step()` method, just like it's done in the above cell (where we do a single `step()`).\n",
        "1. Check the returned `dones` dict for True (yes, episode is terminated) and if True, break out of the loop.\n",
        "\n",
        "**Good luck! :)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QjeiraIPVIv",
        "outputId": "87ab240e-2fb9-4f02-846a-028756ea6f0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_agent1=3\n",
            "action_agent2=3\n",
            "\n",
            "action_agent1=1\n",
            "action_agent2=2\n",
            "\n",
            "action_agent1=3\n",
            "action_agent2=3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DummyTrainer:\n",
        "    \"\"\"Dummy Trainer class used in Exercise #1.\n",
        "\n",
        "    Use its `compute_action` method to get a new action for one of the agents,\n",
        "    given the agent's observation (a single discrete value encoding the field\n",
        "    the agent is currently in).\n",
        "\n",
        "    This means, for a given state observation, just selects a random action.\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_action(self, single_agent_obs=None):\n",
        "        # Returns a random action for a single agent.\n",
        "        return np.random.randint(4)  # Discrete(4) -> return rand int between 0 and 3 (incl. 3).\n",
        "\n",
        "dummy_trainer = DummyTrainer()\n",
        "# Check, whether it's working.\n",
        "for _ in range(3):\n",
        "    # Get action for agent1 (providing agent1's and agent2's positions).\n",
        "    print(\"action_agent1={}\".format(dummy_trainer.compute_action(np.array([0, 99]))))\n",
        "\n",
        "    # Get action for agent2 (providing agent2's and agent1's positions).\n",
        "    print(\"action_agent2={}\".format(dummy_trainer.compute_action(np.array([99, 0]))))\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move the agent over the environment by picking random actions\n",
        "\n",
        "See the agents moving in the environment below!\n",
        "\n",
        "solution here: https://github.com/sven1977/rllib_tutorials/blob/865d77eacb8cb8025abe372d97c47f70aa1d035b/ray_summit_2021/live_coding/exercise_1.py"
      ],
      "metadata": {
        "id": "7QQB7GZfyCxt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f2cBNb5z39j",
        "outputId": "5e0b8353-44a1-49d2-a57d-68c36e85d8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "e94ca5f6a1e7489cb809a7feec2e7dae",
            "4b2d58ec16994b8b8b66ae272b26b670"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e94ca5f6a1e7489cb809a7feec2e7dae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Leave the following as-is. It'll help us with rendering the env in this very cell's output.\n",
        "\n",
        "import time\n",
        "from ipywidgets import Output\n",
        "from IPython import display\n",
        "import time\n",
        "\n",
        "out = Output()\n",
        "display.display(out)\n",
        "\n",
        "with out:\n",
        "\n",
        "    # 1)Instantiate and reset the env.\n",
        "    env = MultiAgentArena()\n",
        "    obs = env.reset()  #places agents on the default state\n",
        "    \n",
        "    # 2) Enter an infinite while loop (to step through the episode).\n",
        "    while True:\n",
        "        # 3) Calculate both agents' actions individually, using dummy_trainer.compute_action([individual agent's obs]). Pass each agen'ts actions\n",
        "        # Note: observations for each agent are stored in dicts (from the _get_obs() method in the env)\n",
        "        a1 = dummy_trainer.compute_action(obs[\"agent1\"])\n",
        "        a2 = dummy_trainer.compute_action(obs[\"agent2\"])\n",
        "\n",
        "        # 4) Compile the actions dict from both individual agents' actions.\n",
        "        actions_dict = {\"agent1\": a1, \"agent2\": a2}\n",
        "        # 5) Send the actions dict to the env's `step()` method to receive: obs, rewards, dones, info dicts\n",
        "        # Send the action-dict to the env to calculate the reward and give the next action (or 'done')\n",
        "        obs, rewards, dones, _ = env.step(actions_dict)\n",
        "\n",
        "        # Get a rendered image from the env.\n",
        "        out.clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(0.1)\n",
        "      \n",
        "        # Don't write any code here (skip directly to 7).\n",
        "        out.clear_output(wait=True)\n",
        "        time.sleep(0.08)\n",
        "        env.render()\n",
        "\n",
        "        # 7) Check, whether the episde is done, if yes, break out of the while loop.\n",
        "        if dones[\"agent1\"]:\n",
        "            break\n",
        "\n",
        "# 8) Run it! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh_3_s1f3HW0"
      },
      "source": [
        "## STEP2: Training with RLlib's PPO\n",
        "\n",
        "We will now train an RL agent with RLlib's PPO. PPO is well-known in the RL community to be one of the most reliable algorithms that works most classes of environments. \n",
        "\n",
        "There are many different algos in RLlib (over 20!) and you can mix match whatever algorithm you like to train your RL agent. This is what makes RLlib a versatile library to use!\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=11pv431GA0frNFZIRfeSp0mMeJ2coTkPW\" width=800>\n",
        "\n",
        "\n",
        "### Initializing Ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q99aq1iV3E5q",
        "outputId": "51e8bc33-6f8a-4899-fa93-2141707b4c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.7.13', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-22_13-53-48_742281_71/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-22_13-53-48_742281_71/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-08-22_13-53-48_742281_71', 'metrics_export_port': 51415, 'gcs_address': '172.28.0.2:56093', 'address': '172.28.0.2:56093', 'node_id': 'fb268bb01881cd45e995b229de0b43237da86e30268c65a42444910c'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pprint\n",
        "import ray\n",
        "\n",
        "# Start a new instance of Ray (when running this tutorial locally) or\n",
        "# connect to an already running one (when running this tutorial through Anyscale).\n",
        "#ray.shutdown()\n",
        "#ray.init()  \n",
        "\n",
        "ray.shutdown()\n",
        "ray.init(ignore_reinit_error=True) #NOTE: It prints the dashboard running on a local port\n",
        "\n",
        "# In case you encounter the following error during our tutorial: `RuntimeError: Maybe you called ray.init twice by accident?`\n",
        "# Try: `ray.shutdown() + ray.init()` or `ray.init(ignore_reinit_error=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpL4Muv58zP8"
      },
      "source": [
        "### Creating an RLlib Trainer (PPOTrainer)\n",
        "\n",
        "The inputs to the trainer are the environment and the config dict\n",
        "\n",
        "In this case, we pass the env inside the config dict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQ67lb35c-y",
        "outputId": "b1ee840f-3457-4ce1-9ccd-d7ed7df7842a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 13:55:13,936\tINFO trainer.py:2333 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
            "2022-08-22 13:55:13,941\tINFO ppo.py:415 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
            "2022-08-22 13:55:13,942\tINFO trainer.py:906 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "2022-08-22 13:55:14,203\tWARNING env.py:217 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
            "2022-08-22 13:55:22,081\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PPOTrainer"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=603)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=603)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=603)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
          ]
        }
      ],
      "source": [
        "# Import a Trainable (one of RLlib's built-in algorithms):\n",
        "# We use the PPO algorithm here b/c its very flexible wrt its supported\n",
        "# action spaces and model types and b/c it learns well almost any problem.\n",
        "from ray.rllib.agents.ppo import PPOTrainer\n",
        "\n",
        "# The trainer's input is a config file\n",
        "# The config file defines the environment and some environment's\n",
        "# options (see environment.py).\n",
        "config = {\n",
        "    \"env\": MultiAgentArena, # \"my_env\" <- if we previously have registered the env with `tune.register_env(\"[name]\", lambda config: [returns env object])`.\n",
        "    \"env_config\": {\n",
        "        \"config\": {\n",
        "            \"width\": 10,\n",
        "            \"height\": 10,\n",
        "            \"ts\": 100, #time steps\n",
        "        },\n",
        "    },\n",
        "\n",
        "    # !PyTorch users!\n",
        "    \"framework\": \"tf\",  # If users have chosen to install torch instead of tf.\n",
        "\n",
        "    \"create_env_on_driver\": True,\n",
        "}\n",
        "# Instantiate the Trainer object using above config.\n",
        "rllib_trainer = PPOTrainer(config=config)\n",
        "rllib_trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udmcMZwI9lkW"
      },
      "source": [
        "### Ready to train with RLlib's PPO algorithm\n",
        "\n",
        "That's it, we are ready to train.\n",
        "Calling `Trainer.train()` will execute a single \"training iteration\".\n",
        "\n",
        "One iteration for most algos involves:\n",
        "\n",
        "1) sampling from the environment(s) (= Rollout)\n",
        "\n",
        "2) using the sampled data (observations, actions taken, rewards) to update the policy model (neural network), such that it would pick better actions in the future, leading to higher rewards.\n",
        "\n",
        "Let's try it out!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVUIlCyU5xA6",
        "outputId": "f7a40ec7-a14c-495d-ebf7-bb8b84541ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 13:59:51,795\tWARNING deprecation.py:47 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent_timesteps_total': 4000,\n",
            " 'counters': {'num_agent_steps_sampled': 4000,\n",
            "              'num_agent_steps_trained': 4000,\n",
            "              'num_env_steps_sampled': 4000,\n",
            "              'num_env_steps_trained': 4000},\n",
            " 'custom_metrics': {},\n",
            " 'date': '2022-08-22_13-59-55',\n",
            " 'done': False,\n",
            " 'episode_len_mean': 100.0,\n",
            " 'episode_media': {},\n",
            " 'episode_reward_max': 11.10000000000002,\n",
            " 'episode_reward_mean': -6.1949999999999985,\n",
            " 'episode_reward_min': -36.90000000000007,\n",
            " 'episodes_this_iter': 20,\n",
            " 'episodes_total': 20,\n",
            " 'experiment_id': '0d8d7143d7824bd2a11ebcbf0a71e6a3',\n",
            " 'hist_stats': {'episode_lengths': [100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100,\n",
            "                                    100],\n",
            "                'episode_reward': [-12.000000000000005,\n",
            "                                   -4.499999999999986,\n",
            "                                   -1.4999999999999927,\n",
            "                                   -7.499999999999994,\n",
            "                                   -25.500000000000014,\n",
            "                                   6.600000000000005,\n",
            "                                   -36.90000000000007,\n",
            "                                   -16.499999999999993,\n",
            "                                   1.200000000000009,\n",
            "                                   2.700000000000016,\n",
            "                                   5.99999999999999,\n",
            "                                   -1.499999999999989,\n",
            "                                   -7.499999999999979,\n",
            "                                   -19.499999999999996,\n",
            "                                   -13.199999999999987,\n",
            "                                   -4.499999999999981,\n",
            "                                   11.10000000000002,\n",
            "                                   2.100000000000008,\n",
            "                                   1.4999999999999711,\n",
            "                                   -4.4999999999999964]},\n",
            " 'hostname': 'b984451c6e0f',\n",
            " 'info': {'learner': {'default_policy': {'custom_metrics': {},\n",
            "                                         'learner_stats': {'cur_kl_coeff': 0.20000000298023224,\n",
            "                                                           'cur_lr': 4.999999873689376e-05,\n",
            "                                                           'entropy': 1.3741271,\n",
            "                                                           'entropy_coeff': 0.0,\n",
            "                                                           'kl': 0.012375374,\n",
            "                                                           'model': {},\n",
            "                                                           'policy_loss': -0.029110864,\n",
            "                                                           'total_loss': 6.039942,\n",
            "                                                           'vf_explained_var': 0.03165453,\n",
            "                                                           'vf_loss': 6.0665774},\n",
            "                                         'num_agent_steps_trained': 128.0}},\n",
            "          'num_agent_steps_sampled': 4000,\n",
            "          'num_agent_steps_trained': 4000,\n",
            "          'num_env_steps_sampled': 4000,\n",
            "          'num_env_steps_trained': 4000},\n",
            " 'iterations_since_restore': 1,\n",
            " 'node_ip': '172.28.0.2',\n",
            " 'num_agent_steps_sampled': 4000,\n",
            " 'num_agent_steps_trained': 4000,\n",
            " 'num_env_steps_sampled': 4000,\n",
            " 'num_env_steps_sampled_this_iter': 4000,\n",
            " 'num_env_steps_trained': 4000,\n",
            " 'num_env_steps_trained_this_iter': 4000,\n",
            " 'num_healthy_workers': 2,\n",
            " 'off_policy_estimator': {},\n",
            " 'perf': {'cpu_util_percent': 8.41304347826087,\n",
            "          'ram_util_percent': 23.149872122762144},\n",
            " 'pid': 71,\n",
            " 'policy_reward_max': {},\n",
            " 'policy_reward_mean': {},\n",
            " 'policy_reward_min': {},\n",
            " 'sampler_perf': {'mean_action_processing_ms': 0.12750296921401355,\n",
            "                  'mean_env_render_ms': 0.0,\n",
            "                  'mean_env_wait_ms': 0.07392988576517476,\n",
            "                  'mean_inference_ms': 1.2248172150267946,\n",
            "                  'mean_raw_obs_processing_ms': 0.3379876320655053},\n",
            " 'sampler_results': {'custom_metrics': {},\n",
            "                     'episode_len_mean': 100.0,\n",
            "                     'episode_media': {},\n",
            "                     'episode_reward_max': 11.10000000000002,\n",
            "                     'episode_reward_mean': -6.1949999999999985,\n",
            "                     'episode_reward_min': -36.90000000000007,\n",
            "                     'episodes_this_iter': 20,\n",
            "                     'hist_stats': {'episode_lengths': [100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100,\n",
            "                                                        100],\n",
            "                                    'episode_reward': [-12.000000000000005,\n",
            "                                                       -4.499999999999986,\n",
            "                                                       -1.4999999999999927,\n",
            "                                                       -7.499999999999994,\n",
            "                                                       -25.500000000000014,\n",
            "                                                       6.600000000000005,\n",
            "                                                       -36.90000000000007,\n",
            "                                                       -16.499999999999993,\n",
            "                                                       1.200000000000009,\n",
            "                                                       2.700000000000016,\n",
            "                                                       5.99999999999999,\n",
            "                                                       -1.499999999999989,\n",
            "                                                       -7.499999999999979,\n",
            "                                                       -19.499999999999996,\n",
            "                                                       -13.199999999999987,\n",
            "                                                       -4.499999999999981,\n",
            "                                                       11.10000000000002,\n",
            "                                                       2.100000000000008,\n",
            "                                                       1.4999999999999711,\n",
            "                                                       -4.4999999999999964]},\n",
            "                     'off_policy_estimator': {},\n",
            "                     'policy_reward_max': {},\n",
            "                     'policy_reward_mean': {},\n",
            "                     'policy_reward_min': {},\n",
            "                     'sampler_perf': {'mean_action_processing_ms': 0.12750296921401355,\n",
            "                                      'mean_env_render_ms': 0.0,\n",
            "                                      'mean_env_wait_ms': 0.07392988576517476,\n",
            "                                      'mean_inference_ms': 1.2248172150267946,\n",
            "                                      'mean_raw_obs_processing_ms': 0.3379876320655053}},\n",
            " 'time_since_restore': 5.87800669670105,\n",
            " 'time_this_iter_s': 5.87800669670105,\n",
            " 'time_total_s': 5.87800669670105,\n",
            " 'timers': {'learn_throughput': 992.136,\n",
            "            'learn_time_ms': 4031.706,\n",
            "            'load_throughput': 14169945.946,\n",
            "            'load_time_ms': 0.282,\n",
            "            'training_iteration_time_ms': 5869.766,\n",
            "            'update_time_ms': 4.364},\n",
            " 'timestamp': 1661176795,\n",
            " 'timesteps_since_restore': 0,\n",
            " 'timesteps_total': 4000,\n",
            " 'training_iteration': 1,\n",
            " 'trial_id': 'default',\n",
            " 'warmup_time': 276.0269057750702}\n"
          ]
        }
      ],
      "source": [
        "# Runs 1 Iteration of Training\n",
        "results = rllib_trainer.train()\n",
        "\n",
        "# Delete the config from the results for clarity.\n",
        "# Only the stats will remain, then.\n",
        "del results[\"config\"]\n",
        "# Pretty print the stats.\n",
        "pprint.pprint(results)\n",
        "del rllib_trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define directory for checkpoints\n",
        "\n",
        "Checkpoints are used for the Rollouts of the policy after training or to resume training."
      ],
      "metadata": {
        "id": "YCAf-1um8hPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "#Main saving directory\n",
        "CHECKPOINT_ROOT = \"tmp/ppo/cart\"\n",
        "\n",
        "# Where checkpoints are written:\n",
        "shutil.rmtree(CHECKPOINT_ROOT, ignore_errors=True, onerror=None)\n",
        "\n",
        "# Where some data will be written and used by Tensorboard below:\n",
        "ray_results = os.getenv(\"HOME\") + \"/ray_results/\"\n",
        "shutil.rmtree(ray_results, ignore_errors=True, onerror=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "K48UFdq18frP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another alternative is to train for a max number of iterations\n",
        "# Training\n",
        "#https://github.com/anyscale/academy/blob/main/ray-rllib/explore-rllib/01-Application-Cart-Pole.ipynb\n",
        "\n",
        "# Similarly, we can save the training stats on list to inspect\n",
        "N_ITER = 3 #only 3 iterations to show the idea   (By default, training runs for 10 iterations).\n",
        "results = []\n",
        "episode_data = []\n",
        "episode_json = []\n",
        "\n",
        "agent = PPOTrainer(config=config)\n",
        "\n",
        "for n in range(N_ITER):\n",
        "    result = agent.train() # each call to agent.train() returns a object containing information that we will inspect below\n",
        "    results.append(result)\n",
        "    \n",
        "    episode = {'n': n, \n",
        "               'episode_reward_min': result['episode_reward_min'], \n",
        "               'episode_reward_mean':result['episode_reward_mean'], \n",
        "               'episode_reward_max': result['episode_reward_max'],  \n",
        "               'episode_len_mean':   result['episode_len_mean']}\n",
        "    \n",
        "    episode_data.append(episode)\n",
        "    episode_json.append(json.dumps(episode))\n",
        "    file_name = agent.save(CHECKPOINT_ROOT)\n",
        "    \n",
        "    print(f'{n:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}. Checkpoint saved to {file_name}')\n"
      ],
      "metadata": {
        "id": "5LJbljSQ7uQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspect Training results\n"
      ],
      "metadata": {
        "id": "NLnqB9K3-i8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the results object\n",
        "results"
      ],
      "metadata": {
        "id": "HTIijQ7t-sBM",
        "outputId": "051d158a-41e9-4b7e-a352-8accbe75f311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert to df and inspect\n",
        "df = pd.DataFrame(data=episode_data)\n",
        "df"
      ],
      "metadata": {
        "id": "cDj-hb8Y-vvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot results\n",
        "df.plot(x=\"n\", y=[\"episode_reward_mean\", \"episode_reward_min\", \"episode_reward_max\"], secondary_y=True)"
      ],
      "metadata": {
        "id": "vPYonBFg-02i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out the policy and model to see the results of training in detail…"
      ],
      "metadata": {
        "id": "ekeGJKtj-9OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "policy = agent.get_policy()\n",
        "model = policy.model\n",
        "\n",
        "pprint.pprint(model.variables())\n",
        "pprint.pprint(model.value_function())\n",
        "\n",
        "print(model.base_model.summary())"
      ],
      "metadata": {
        "id": "RPU8b3xM--y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-0L4KcJAu2B"
      },
      "source": [
        "## Exercise 2: Training with Multiple Policies\n",
        "\n",
        "We need a different policy for each agent because they have a different objective (and thus, a different reward scheme).\n",
        "\n",
        "So far, our experiment has been ill-configured, because both\n",
        "agents, which should behave differently due to their different\n",
        "tasks and reward functions, learn the same policy: the \"default_policy\",\n",
        "which RLlib always provides if you don't configure anything else.\n",
        "\n",
        "Remember that RLlib does not know at Trainer setup time, how many and which agents the environment will \"produce\". Agent control (adding agents, removing them, terminating episodes for agents) is entirely in the Env's hands.\n",
        "Let's fix our single policy problem and introduce the \"multiagent\" API.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1rsRMLN8KyEHKS4XCcjRmUW19kpRjqB8z\" width=800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml_yZPxqBri1"
      },
      "source": [
        "In order to turn on RLlib's multi-agent functionality, follow these instructions:\n",
        "\n",
        "1. A policies definition dict, mapping policy IDs (e.g. \"policy1\") to 4-tuples consisting of 1) policy class (None for using the default class), 2) observation space, 3) action space, and 4) config overrides (empty dict for no overrides and using the Trainer's main config dict).\n",
        "1. A policy mapping function, mapping agent IDs (e.g. a string like \"agent1\", produced by the environment in the returned observation/rewards/dones-dicts) to a policy ID (another string, e.g. \"policy1\").\n",
        "1. Pass in the policy mapping function and policy configs into the Trainer config.\n",
        "1. Train!\n",
        "\n",
        "If stucked, https://docs.ray.io/en/latest/rllib-env.html#multi-agent-and-hierarchical provides a great example.\n",
        "\n",
        "**Good luck! :)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH_QP5MbN8Iz",
        "outputId": "90bb4fe6-6836-47b7-ac07-45761cad0a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.7.13', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-22_14-33-58_707870_71/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-22_14-33-58_707870_71/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-08-22_14-33-58_707870_71', 'metrics_export_port': 65525, 'gcs_address': '172.28.0.2:50579', 'address': '172.28.0.2:50579', 'node_id': '65eccfa059657088fc7f86a2e96aaf7f6290b7a265df8e530b74ca9f'})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Run this if neccessary\n",
        "ray.shutdown()\n",
        "ray.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFeuLIe26CZ4",
        "outputId": "b2e2d37c-2896-4ee9-cfb5-2d20c5b873f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'create_env_on_driver': True,\n",
            " 'env': <class '__main__.MultiAgentArena'>,\n",
            " 'env_config': {'config': {'height': 10, 'ts': 100, 'width': 10}},\n",
            " 'framework': 'tf',\n",
            " 'multiagent': {'policies': {'policy1': (None,\n",
            "                                         MultiDiscrete([100 100]),\n",
            "                                         Discrete(4),\n",
            "                                         {}),\n",
            "                             'policy2': (None,\n",
            "                                         MultiDiscrete([100 100]),\n",
            "                                         Discrete(4),\n",
            "                                         {'lr': 0.0002})},\n",
            "                'policy_mapping_fn': <function policy_mapping_fn at 0x7f2a924af830>}}\n",
            "\n",
            "agent1 is now mapped to policy1\n",
            "agent2 is now mapped to policy2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 14:53:42,340\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2\n",
        "# 1) Define the policies definition dict:\n",
        "\n",
        "  # Each policy in there is defined by its ID (key) mapping to a 4-tuple (value):\n",
        "  # - Policy class ('None' for using the \"default\" class, e.g. PPOTFPolicy for PPO+tf or PPOTorchPolicy for PPO+torch). By default is a fully connected network\n",
        "  # - obs-space (we get this directly from our already created env object).\n",
        "  # - act-space (we get this directly from our already created env object).\n",
        "  # - config-overrides dict (leave empty for using the Trainer's config as-is). The empty dict is to use the 'config' dict we have defined before. We can override any dict param here.\n",
        "\n",
        "policies = {\n",
        "    \"policy1\": (None, env.observation_space,env.action_space, {}),\n",
        "    \"policy2\": (None, env.observation_space,env.action_space,{'lr':0.0002}) #smaller 'lr' it will learn slower w.r.t policy 1\n",
        " }\n",
        "\n",
        "# Note that now we won't have a \"default_policy\" anymore, just \"policy1\" and \"policy2\".\n",
        "\n",
        "# 2) Defines an agent->policy mapping function.\n",
        "# The mapping here is M (agents) -> N (policies), where M >= N.\n",
        "def policy_mapping_fn(agent_id: str) -> str:\n",
        "    # Make sure agent ID is valid.\n",
        "    assert agent_id in [\"agent1\", \"agent2\"], f\"ERROR: invalid agent ID {agent_id}!\"\n",
        "\n",
        "    return 'policy1' if agent_id == 'agent1' else 'policy2'\n",
        "\n",
        "config = {\n",
        "    \"env\": MultiAgentArena,  # \"my_env\" <- if we previously have registered the env with `tune.register_env(\"[name]\", lambda config: [returns env object])`.\n",
        "    \"env_config\": {\n",
        "        \"config\": {\n",
        "            \"width\": 10,\n",
        "            \"height\": 10,\n",
        "            \"ts\": 100,\n",
        "        },\n",
        "    },\n",
        "    # !PyTorch users!\n",
        "    \"framework\": \"tf\",  # If users have chosen to install torch instead of tf.\n",
        "    \"create_env_on_driver\": True,\n",
        "}\n",
        "\n",
        "# 3) Adding the above to our config.\n",
        "### Modify Code here ####\n",
        "config.update({\n",
        "    \"multiagent\": {\n",
        "        \"policies\": policies,\n",
        "        \"policy_mapping_fn\": policy_mapping_fn,\n",
        "        # We'll leave this empty: Means, we train both policy1 and policy2.\n",
        "        # \"policies_to_train\": policies_to_train,\n",
        "    },\n",
        "})\n",
        "\n",
        "pprint.pprint(config)\n",
        "print()\n",
        "print(f\"agent1 is now mapped to {policy_mapping_fn('agent1')}\")\n",
        "print(f\"agent2 is now mapped to {policy_mapping_fn('agent2')}\")\n",
        "\n",
        "#rllib_trainer = PPOTrainer(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate our Trainer (we cannot just change the config on-the-fly).\n",
        "rllib_trainer.stop()\n",
        "\n",
        "# Using our updated (now multiagent!) config dict.\n",
        "rllib_trainer = PPOTrainer(config=config)\n",
        "rllib_trainer"
      ],
      "metadata": {
        "id": "sHx4oTd7E1dY",
        "outputId": "c0135700-7a10-47be-fef3-bc45ab420eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:02:30,531\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PPOTrainer"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are setup correctly with two policies as per our \"multiagent\" config, let's call train() on the new Trainer several times (what about 10 times?)."
      ],
      "metadata": {
        "id": "HZiq3XlaFEKN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS_HsAcTApSb",
        "outputId": "19e0e8c6-0cf1-440e-ca4c-c3efca64fd7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=1829)\u001b[0m 2022-08-22 14:54:58,055\tWARNING deprecation.py:47 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, worker, **kwargs)` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration=1: R(\"return\")=-13.612500000000006\n",
            "Iteration=2: R(\"return\")=-8.054999999999996\n",
            "Iteration=3: R(\"return\")=-4.496999999999989\n",
            "Iteration=4: R(\"return\")=-0.6929999999999857\n",
            "Iteration=5: R(\"return\")=0.3600000000000152\n",
            "Iteration=6: R(\"return\")=1.5330000000000152\n",
            "Iteration=7: R(\"return\")=1.1910000000000154\n",
            "Iteration=8: R(\"return\")=1.8120000000000127\n",
            "Iteration=9: R(\"return\")=2.922000000000009\n",
            "Iteration=10: R(\"return\")=4.431000000000008\n"
          ]
        }
      ],
      "source": [
        "# 4) Run `train()` n times. Repeatedly call `train()` now to see rewards increase.\n",
        "# Move on once you see (agent1 + agent2) episode rewards of 10.0 or more.\n",
        "for _ in range(10):\n",
        "    results = rllib_trainer.train()\n",
        "    print(f\"Iteration={rllib_trainer.iteration}: R(\\\"return\\\")={results['episode_reward_mean']}\")  #will print out the cummulative reward for each iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1OoY9xnFzhy"
      },
      "source": [
        "Now that we are setup correctly with two policies as per our \"multiagent\" config, let's call `train()` on the new Trainer several times (what about 10 times?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5ReNk_4F3EZ",
        "outputId": "8bc9ef40-b498-4467-9c59-8d301c4d2455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration=11: R(\"return\")=5.541000000000015 R1=13.55 R2=-8.008999999999986\n",
            "Iteration=12: R(\"return\")=6.414000000000014 R1=14.5 R2=-8.085999999999986\n",
            "Iteration=13: R(\"return\")=8.337000000000014 R1=16.28 R2=-7.942999999999986\n",
            "Iteration=14: R(\"return\")=9.126000000000015 R1=16.695 R2=-7.568999999999986\n",
            "Iteration=15: R(\"return\")=10.893000000000013 R1=18.165 R2=-7.271999999999986\n",
            "Iteration=16: R(\"return\")=11.394000000000013 R1=18.105 R2=-6.710999999999989\n",
            "Iteration=17: R(\"return\")=13.155000000000014 R1=19.8 R2=-6.644999999999987\n",
            "Iteration=18: R(\"return\")=13.287000000000011 R1=20.185 R2=-6.897999999999987\n",
            "Iteration=19: R(\"return\")=12.699000000000012 R1=20.455 R2=-7.755999999999987\n",
            "Iteration=20: R(\"return\")=12.816000000000011 R1=19.56 R2=-6.743999999999987\n"
          ]
        }
      ],
      "source": [
        "# Do another loop, but this time, we will print out each policies' individual rewards.\n",
        "for _ in range(10):\n",
        "    results = rllib_trainer.train()\n",
        "    r1 = results['policy_reward_mean']['policy1']\n",
        "    r2 = results['policy_reward_mean']['policy2']\n",
        "    r = r1 + r2\n",
        "    print(f\"Iteration={rllib_trainer.iteration}: R(\\\"return\\\")={r} R1={r1} R2={r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ginSlspOoPX"
      },
      "source": [
        "## Evaluating Multiagent PPO Trainer\n",
        "\n",
        "Now that we are done training with PPO, let's evaluate how the agents behave, using our code in Exercise 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMnpjrxKF7b4",
        "outputId": "af6703cf-8980-4d2f-fc89-5f683bb54391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "0e348ce501c54e0ab7b7bc59c582726a",
            "251a8af5c17344b08b3c119fdb0a2109"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e348ce501c54e0ab7b7bc59c582726a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "out = Output()\n",
        "display.display(out)\n",
        "\n",
        "with out:\n",
        "    env = MultiAgentArena()\n",
        "    obs = env.reset()\n",
        "    while True:\n",
        "        a1 = rllib_trainer.compute_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
        "        a2 = rllib_trainer.compute_action(obs[\"agent2\"], policy_id=\"policy2\")    \n",
        "        obs, rewards, dones, _ = env.step({\"agent1\": a1, \"agent2\": a2})\n",
        "        out.clear_output(wait=True)\n",
        "        time.sleep(0.08)\n",
        "        env.render()\n",
        "        if dones[\"agent1\"]:\n",
        "          break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85XForDFSEIo"
      },
      "source": [
        "#### !OPTIONAL HACK!\n",
        "\n",
        "Feel free to play around with the following code in order to learn how RLlib - under the hood - calculates actions from the environment's observations using Policies and their model(s) inside our Trainer object):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's actually \"look inside\" our Trainer to see what's in there.\n",
        "from ray.rllib.utils.numpy import softmax\n",
        "\n",
        "# To get to one of the policies inside the Trainer, use `Trainer.get_policy([policy ID])`:\n",
        "policy = rllib_trainer.get_policy(\"policy1\")\n",
        "print(f\"Our (only!) Policy right now is: {policy}\")\n",
        "\n",
        "# To get to the model inside any policy, do:\n",
        "model = policy.model\n",
        "#print(f\"Our Policy's model is: {model}\")\n",
        "\n",
        "# Print out the policy's action and observation spaces.\n",
        "print(f\"Our Policy's observation space is: {policy.observation_space}\")\n",
        "print(f\"Our Policy's action space is: {policy.action_space}\")\n",
        "\n",
        "# Produce a random obervation (B=1; batch of size 1).\n",
        "obs = np.array([policy.observation_space.sample()])\n",
        "# Alternatively for PyTorch:\n",
        "#import torch\n",
        "#obs = torch.from_numpy(obs)\n",
        "\n",
        "# Get the action logits (as tf tensor).\n",
        "# If you are using torch, you would get a torch tensor here.\n",
        "logits, _ = model({\"obs\": obs})\n",
        "logits\n",
        "\n",
        "# Numpyize the tensor by running `logits` through the Policy's own tf.Session.\n",
        "logits_np = policy.get_session().run(logits)\n",
        "# For torch, you can simply do: `logits_np = logits.detach().cpu().numpy()`.\n",
        "\n",
        "# Convert logits into action probabilities and remove the B=1.\n",
        "action_probs = np.squeeze(softmax(logits_np))\n",
        "\n",
        "# Sample an action, using the probabilities.\n",
        "action = np.random.choice([0, 1, 2, 3], p=action_probs)\n",
        "\n",
        "# Print out the action.\n",
        "print(f\"sampled action={action}\")"
      ],
      "metadata": {
        "id": "kNEpSX5xFUc8",
        "outputId": "d09cdd13-8251-41a2-8311-83204c5a6514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our (only!) Policy right now is: PPOTFPolicy\n",
            "Our Policy's observation space is: Box([-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1.], (200,), float32)\n",
            "Our Policy's action space is: Discrete(4)\n",
            "sampled action=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and restoring a trained Trainer.\n",
        "Currently, `rllib_trainer` is in an already trained state.\n",
        "It holds optimized weights in its Policy's model that allow it to act\n",
        "already somewhat smart in our environment when given an observation.\n",
        "\n",
        "However, if we closed this notebook right now, all the effort would have been for nothing.\n",
        "Let's therefore save the state of our trainer to disk for later!"
      ],
      "metadata": {
        "id": "FpDhogiJFe3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the `Trainer.save()` method to create a checkpoint.\n",
        "checkpoint_file = rllib_trainer.save()\n",
        "print(f\"Trainer (at iteration {rllib_trainer.iteration} was saved in '{checkpoint_file}'!\")\n",
        "\n",
        "# Here is what a checkpoint directory contains:\n",
        "print(\"The checkpoint directory contains the following files:\")\n",
        "import os\n",
        "os.listdir(os.path.dirname(checkpoint_file))"
      ],
      "metadata": {
        "id": "t4-0DPk_Ffoe",
        "outputId": "8e80c6ee-d642-4071-e7d1-8ad2b3cba5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer (at iteration 0 was saved in '/root/ray_results/PPOTrainer_MultiAgentArena_2022-08-22_15-02-243up9g08g/checkpoint_000000/checkpoint-0'!\n",
            "The checkpoint directory contains the following files:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.is_checkpoint', 'checkpoint-0.tune_metadata', 'checkpoint-0']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restoring and evaluating a Trainer\n",
        "In the following cell, we'll learn how to restore a saved Trainer from a checkpoint file.\n",
        "\n",
        "We'll also evaluate a completely new Trainer (should act more or less randomly) vs an already trained one (the one we just restored from the created checkpoint file)."
      ],
      "metadata": {
        "id": "jgkGPWJbFmY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretend, we wanted to pick up training from a previous run:\n",
        "new_trainer = PPOTrainer(config=config)\n",
        "# Evaluate the new trainer (this should yield random results).\n",
        "results = new_trainer.evaluate()\n",
        "print(f\"Evaluating new trainer: R={results['evaluation']['episode_reward_mean']}\")\n",
        "\n",
        "# Restoring the trained state into the `new_trainer` object.\n",
        "print(f\"Before restoring: Trainer is at iteration={new_trainer.iteration}\")\n",
        "new_trainer.restore(checkpoint_file)\n",
        "print(f\"After restoring: Trainer is at iteration={new_trainer.iteration}\")\n",
        "\n",
        "# Evaluate again (this should yield results we saw after having trained our saved agent).\n",
        "results = new_trainer.evaluate()\n",
        "print(f\"Evaluating restored trainer: R={results['evaluation']['episode_reward_mean']}\")"
      ],
      "metadata": {
        "id": "4CtIWo8BFhwi",
        "outputId": "c753f216-4765-4937-c1e5-d8158d72e6e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:05:47,020\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
            "2022-08-22 15:05:47,026\tWARNING deprecation.py:47 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, worker, **kwargs)` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h55m52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:05:55,272\tINFO trainable.py:589 -- Restored on 172.28.0.2 from checkpoint: /root/ray_results/PPOTrainer_MultiAgentArena_2022-08-22_15-02-243up9g08g/checkpoint_000000/checkpoint-0\n",
            "2022-08-22 15:05:55,274\tINFO trainable.py:597 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': None, '_time_total': 0.0, '_episodes_total': None}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating new trainer: R=-9.855000000000008\n",
            "Before restoring: Trainer is at iteration=0\n",
            "After restoring: Trainer is at iteration=0\n",
            "Evaluating restored trainer: R=-8.909999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to release all resources from a Trainer, you can use a Trainer's `stop()` method.\n",
        "You should definitley run this cell as it frees resources that we'll need later in this tutorial, when we'll do parallel hyperparameter sweeps."
      ],
      "metadata": {
        "id": "8K8zWp4TFtwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rllib_trainer.stop()\n",
        "new_trainer.stop()"
      ],
      "metadata": {
        "id": "2ZphOtG_FpMQ",
        "outputId": "d1b31e79-bdf2-4b09-8eae-f49ecdacf69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=2073)\u001b[0m E0822 15:06:15.470895777    2112 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=2072)\u001b[0m E0822 15:06:15.471469311    2096 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
            "\u001b[2m\u001b[36m(pid=2238)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2238)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2238)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "\u001b[2m\u001b[36m(pid=2239)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2239)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2239)\u001b[0m experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=2238)\u001b[0m 2022-08-22 15:06:22,973\tWARNING env.py:217 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving stuff to the professional level: RLlib in connection w/ Ray Tune\n",
        "\n",
        "Running any experiments through Ray Tune is the recommended way of doing things with RLlib. If you look at our\n",
        "<a href=\"https://github.com/ray-project/ray/tree/master/rllib/examples\">examples scripts folder</a>, you will see that almost all of the scripts use Ray Tune to run the particular RLlib workload demonstrated in each script.\n",
        "\n",
        "\n",
        "When setting up hyperparameter sweeps for Tune, we'll do this in our already familiar config dict.\n",
        "\n",
        "So let's take a quick look at our PPO algo's default config to understand, which hyperparameters we may want to play around with:"
      ],
      "metadata": {
        "id": "LAQNCk2kF7qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration dicts and Ray Tune.\n",
        "# Where are the default configuration dicts stored?\n",
        "\n",
        "# PPO algorithm:\n",
        "from ray.rllib.agents.ppo import DEFAULT_CONFIG as PPO_DEFAULT_CONFIG\n",
        "print(f\"PPO's default config is:\")\n",
        "pprint.pprint(PPO_DEFAULT_CONFIG)\n",
        "\n",
        "# DQN algorithm:\n",
        "#from ray.rllib.agents.dqn import DEFAULT_CONFIG as DQN_DEFAULT_CONFIG\n",
        "#print(f\"DQN's default config is:\")\n",
        "#pprint.pprint(DQN_DEFAULT_CONFIG)\n",
        "\n",
        "# Common (all algorithms).\n",
        "#from ray.rllib.agents.trainer import COMMON_CONFIG\n",
        "#print(f\"RLlib Trainer's default config is:\")\n",
        "#pprint.pprint(COMMON_CONFIG)"
      ],
      "metadata": {
        "id": "HqjeRd6IFwjs",
        "outputId": "5d6edac8-80c8-4664-f9a0-b4f21a6a39a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO's default config is:\n",
            "{'_disable_action_flattening': False,\n",
            " '_disable_execution_plan_api': True,\n",
            " '_disable_preprocessor_api': False,\n",
            " '_fake_gpus': False,\n",
            " '_tf_policy_handles_more_than_one_loss': False,\n",
            " 'action_space': None,\n",
            " 'actions_in_input_normalized': False,\n",
            " 'always_attach_evaluation_results': False,\n",
            " 'batch_mode': 'truncate_episodes',\n",
            " 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>,\n",
            " 'clip_actions': False,\n",
            " 'clip_param': 0.3,\n",
            " 'clip_rewards': None,\n",
            " 'collect_metrics_timeout': -1,\n",
            " 'compress_observations': False,\n",
            " 'create_env_on_driver': False,\n",
            " 'custom_eval_function': None,\n",
            " 'custom_resources_per_worker': {},\n",
            " 'disable_env_checking': False,\n",
            " 'eager_max_retraces': 20,\n",
            " 'eager_tracing': False,\n",
            " 'entropy_coeff': 0.0,\n",
            " 'entropy_coeff_schedule': None,\n",
            " 'env': None,\n",
            " 'env_config': {},\n",
            " 'env_task_fn': None,\n",
            " 'evaluation_config': {},\n",
            " 'evaluation_duration': 10,\n",
            " 'evaluation_duration_unit': 'episodes',\n",
            " 'evaluation_interval': None,\n",
            " 'evaluation_num_episodes': -1,\n",
            " 'evaluation_num_workers': 0,\n",
            " 'evaluation_parallel_to_training': False,\n",
            " 'exploration_config': {'type': 'StochasticSampling'},\n",
            " 'explore': True,\n",
            " 'extra_python_environs_for_driver': {},\n",
            " 'extra_python_environs_for_worker': {},\n",
            " 'fake_sampler': False,\n",
            " 'framework': 'tf',\n",
            " 'gamma': 0.99,\n",
            " 'grad_clip': None,\n",
            " 'horizon': None,\n",
            " 'ignore_worker_failures': False,\n",
            " 'in_evaluation': False,\n",
            " 'input': 'sampler',\n",
            " 'input_config': {},\n",
            " 'input_evaluation': ['is', 'wis'],\n",
            " 'keep_per_episode_custom_metrics': False,\n",
            " 'kl_coeff': 0.2,\n",
            " 'kl_target': 0.01,\n",
            " 'lambda': 1.0,\n",
            " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
            "                           'intra_op_parallelism_threads': 8},\n",
            " 'log_level': 'WARN',\n",
            " 'log_sys_usage': True,\n",
            " 'logger_config': None,\n",
            " 'lr': 5e-05,\n",
            " 'lr_schedule': None,\n",
            " 'metrics_episode_collection_timeout_s': 180,\n",
            " 'metrics_num_episodes_for_smoothing': 100,\n",
            " 'metrics_smoothing_episodes': -1,\n",
            " 'min_iter_time_s': -1,\n",
            " 'min_sample_timesteps_per_reporting': None,\n",
            " 'min_time_s_per_reporting': None,\n",
            " 'min_train_timesteps_per_reporting': None,\n",
            " 'model': {'_disable_action_flattening': False,\n",
            "           '_disable_preprocessor_api': False,\n",
            "           '_time_major': False,\n",
            "           '_use_default_native_models': False,\n",
            "           'attention_dim': 64,\n",
            "           'attention_head_dim': 32,\n",
            "           'attention_init_gru_gate_bias': 2.0,\n",
            "           'attention_memory_inference': 50,\n",
            "           'attention_memory_training': 50,\n",
            "           'attention_num_heads': 1,\n",
            "           'attention_num_transformer_units': 1,\n",
            "           'attention_position_wise_mlp_dim': 32,\n",
            "           'attention_use_n_prev_actions': 0,\n",
            "           'attention_use_n_prev_rewards': 0,\n",
            "           'conv_activation': 'relu',\n",
            "           'conv_filters': None,\n",
            "           'custom_action_dist': None,\n",
            "           'custom_model': None,\n",
            "           'custom_model_config': {},\n",
            "           'custom_preprocessor': None,\n",
            "           'dim': 84,\n",
            "           'fcnet_activation': 'tanh',\n",
            "           'fcnet_hiddens': [256, 256],\n",
            "           'framestack': True,\n",
            "           'free_log_std': False,\n",
            "           'grayscale': False,\n",
            "           'lstm_cell_size': 256,\n",
            "           'lstm_use_prev_action': False,\n",
            "           'lstm_use_prev_action_reward': -1,\n",
            "           'lstm_use_prev_reward': False,\n",
            "           'max_seq_len': 20,\n",
            "           'no_final_linear': False,\n",
            "           'post_fcnet_activation': 'relu',\n",
            "           'post_fcnet_hiddens': [],\n",
            "           'use_attention': False,\n",
            "           'use_lstm': False,\n",
            "           'vf_share_layers': False,\n",
            "           'zero_mean': True},\n",
            " 'monitor': -1,\n",
            " 'multiagent': {'count_steps_by': 'env_steps',\n",
            "                'observation_fn': None,\n",
            "                'policies': {},\n",
            "                'policies_to_train': None,\n",
            "                'policy_map_cache': None,\n",
            "                'policy_map_capacity': 100,\n",
            "                'policy_mapping_fn': None,\n",
            "                'replay_mode': 'independent'},\n",
            " 'no_done_at_end': False,\n",
            " 'normalize_actions': True,\n",
            " 'num_cpus_for_driver': 1,\n",
            " 'num_cpus_per_worker': 1,\n",
            " 'num_envs_per_worker': 1,\n",
            " 'num_gpus': 0,\n",
            " 'num_gpus_per_worker': 0,\n",
            " 'num_sgd_iter': 30,\n",
            " 'num_workers': 2,\n",
            " 'observation_filter': 'NoFilter',\n",
            " 'observation_space': None,\n",
            " 'optimizer': {},\n",
            " 'output': None,\n",
            " 'output_compress_columns': ['obs', 'new_obs'],\n",
            " 'output_config': {},\n",
            " 'output_max_file_size': 67108864,\n",
            " 'placement_strategy': 'PACK',\n",
            " 'postprocess_inputs': False,\n",
            " 'preprocessor_pref': 'deepmind',\n",
            " 'record_env': False,\n",
            " 'recreate_failed_workers': False,\n",
            " 'remote_env_batch_wait_ms': 0,\n",
            " 'remote_worker_envs': False,\n",
            " 'render_env': False,\n",
            " 'rollout_fragment_length': 200,\n",
            " 'sample_async': False,\n",
            " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
            " 'seed': None,\n",
            " 'sgd_minibatch_size': 128,\n",
            " 'shuffle_buffer_size': 0,\n",
            " 'shuffle_sequences': True,\n",
            " 'simple_optimizer': -1,\n",
            " 'soft_horizon': False,\n",
            " 'synchronize_filters': True,\n",
            " 'tf_session_args': {'allow_soft_placement': True,\n",
            "                     'device_count': {'CPU': 1},\n",
            "                     'gpu_options': {'allow_growth': True},\n",
            "                     'inter_op_parallelism_threads': 2,\n",
            "                     'intra_op_parallelism_threads': 2,\n",
            "                     'log_device_placement': False},\n",
            " 'timesteps_per_iteration': 0,\n",
            " 'train_batch_size': 4000,\n",
            " 'use_critic': True,\n",
            " 'use_gae': True,\n",
            " 'vf_clip_param': 10.0,\n",
            " 'vf_loss_coeff': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's do a very simple grid-search over two learning rates with tune.run().\n",
        "\n",
        "In particular, we will try the learning rates 0.00005 and 0.5 using `tune.grid_search([...])`\n",
        "inside our config dict:"
      ],
      "metadata": {
        "id": "Ts0Obs0CGZYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plugging in Ray Tune.\n",
        "# Note that this is the recommended way to run any experiments with RLlib.\n",
        "# Reasons:\n",
        "# - Tune allows you to do hyperparameter tuning in a user-friendly way\n",
        "#   and at large scale!\n",
        "# - Tune automatically allocates needed resources for the different\n",
        "#   hyperparam trials and experiment runs on a cluster.\n",
        "\n",
        "from ray import tune\n",
        "\n",
        "# Running stuff with tune, we can re-use the exact\n",
        "# same config that we used when working with RLlib directly!\n",
        "tune_config = config.copy()\n",
        "\n",
        "# Let's add our first hyperparameter search via our config.\n",
        "# How about we try two different learning rates? Let's say 0.00005 and 0.5 (ouch!).\n",
        "tune_config[\"lr\"] = tune.grid_search([0.0001, 0.5])  # <- 0.5? again: ouch!\n",
        "tune_config[\"train_batch_size\"] = tune.grid_search([3000, 4000])\n",
        "\n",
        "# Now that we will run things \"automatically\" through tune, we have to\n",
        "# define one or more stopping criteria.\n",
        "# Tune will stop the run, once any single one of the criteria is matched (not all of them!).\n",
        "stop = {\n",
        "    # Note that the keys used here can be anything present in the above `rllib_trainer.train()` output dict.\n",
        "    \"training_iteration\": 5,\n",
        "    \"episode_reward_mean\": 20.0,\n",
        "}\n",
        "\n",
        "# \"PPO\" is a registered name that points to RLlib's PPOTrainer.\n",
        "# See `ray/rllib/agents/registry.py`\n",
        "\n",
        "# Run a simple experiment until one of the stopping criteria is met.\n",
        "tune.run(\n",
        "    \"PPO\",\n",
        "    config=tune_config,\n",
        "    stop=stop,\n",
        "\n",
        "    # Note that no trainers will be returned from this call here.\n",
        "    # Tune will create n Trainers internally, run them in parallel and destroy them at the end.\n",
        "    # However, you can ...\n",
        "    checkpoint_at_end=True,  # ... create a checkpoint when done.\n",
        "    checkpoint_freq=10,  # ... create a checkpoint every 10 training iterations.\n",
        ")"
      ],
      "metadata": {
        "id": "HiomVdDvGV6v",
        "outputId": "fbe3be6a-7ed6-4809-fc3b-22d164d2224c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:32 (running for 00:00:05.19)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:37 (running for 00:00:10.19)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:42 (running for 00:00:15.21)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:47 (running for 00:00:20.22)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:52 (running for 00:00:25.24)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:09:57 (running for 00:00:30.25)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:02 (running for 00:00:35.26)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:07 (running for 00:00:40.26)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:12 (running for 00:00:45.28)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:17 (running for 00:00:50.28)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:22 (running for 00:00:55.30)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:27 (running for 00:01:00.30)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:32 (running for 00:01:05.32)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:10:37,750\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:37 (running for 00:01:10.32)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:42 (running for 00:01:15.34)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:47 (running for 00:01:20.34)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:52 (running for 00:01:25.35)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:10:57 (running for 00:01:30.36)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:02 (running for 00:01:35.37)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:07 (running for 00:01:40.37)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:12 (running for 00:01:45.39)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:17 (running for 00:01:50.39)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:22 (running for 00:01:55.41)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:27 (running for 00:02:00.41)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:32 (running for 00:02:05.42)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:11:37,858\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:37 (running for 00:02:10.43)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:42 (running for 00:02:15.44)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:47 (running for 00:02:20.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:52 (running for 00:02:25.46)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:11:57 (running for 00:02:30.47)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:02 (running for 00:02:35.49)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:07 (running for 00:02:40.49)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:12 (running for 00:02:45.50)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:17 (running for 00:02:50.51)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:22 (running for 00:02:55.52)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:27 (running for 00:03:00.52)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:32 (running for 00:03:05.54)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:12:37,973\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:37 (running for 00:03:10.55)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:42 (running for 00:03:15.56)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:47 (running for 00:03:20.56)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:53 (running for 00:03:25.58)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:12:58 (running for 00:03:30.58)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:03 (running for 00:03:35.59)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:08 (running for 00:03:40.60)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:13 (running for 00:03:45.61)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:18 (running for 00:03:50.61)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:23 (running for 00:03:55.62)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:28 (running for 00:04:00.63)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:33 (running for 00:04:05.64)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:13:38,073\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:38 (running for 00:04:10.65)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:43 (running for 00:04:15.66)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:48 (running for 00:04:20.67)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:53 (running for 00:04:25.68)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:13:58 (running for 00:04:30.69)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:03 (running for 00:04:35.70)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:08 (running for 00:04:40.70)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:13 (running for 00:04:45.72)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:18 (running for 00:04:50.72)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:23 (running for 00:04:55.74)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:28 (running for 00:05:00.74)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:33 (running for 00:05:05.76)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:14:38,190\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:38 (running for 00:05:10.76)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:43 (running for 00:05:15.78)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:48 (running for 00:05:20.78)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:53 (running for 00:05:25.80)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:14:58 (running for 00:05:30.80)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:03 (running for 00:05:35.82)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:08 (running for 00:05:40.82)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:13 (running for 00:05:45.84)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:18 (running for 00:05:50.85)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:23 (running for 00:05:55.86)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:28 (running for 00:06:00.87)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:33 (running for 00:06:05.88)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:15:38,309\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:38 (running for 00:06:10.88)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:43 (running for 00:06:15.90)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:48 (running for 00:06:20.91)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:53 (running for 00:06:25.92)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:15:58 (running for 00:06:30.92)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:03 (running for 00:06:35.94)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:08 (running for 00:06:40.94)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:13 (running for 00:06:46.10)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:18 (running for 00:06:51.10)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:23 (running for 00:06:56.11)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:28 (running for 00:07:01.11)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:33 (running for 00:07:06.13)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:16:38,565\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:38 (running for 00:07:11.14)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:43 (running for 00:07:16.15)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:48 (running for 00:07:21.16)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:53 (running for 00:07:26.18)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:16:58 (running for 00:07:31.18)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:03 (running for 00:07:36.20)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:08 (running for 00:07:41.20)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:13 (running for 00:07:46.21)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:18 (running for 00:07:51.22)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:23 (running for 00:07:56.23)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:28 (running for 00:08:01.24)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:33 (running for 00:08:06.25)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:17:38,688\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:38 (running for 00:08:11.26)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:43 (running for 00:08:16.28)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:48 (running for 00:08:21.28)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:53 (running for 00:08:26.30)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:17:58 (running for 00:08:31.31)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:03 (running for 00:08:36.32)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:08 (running for 00:08:41.33)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:13 (running for 00:08:46.34)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:18 (running for 00:08:51.35)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:23 (running for 00:08:56.37)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:28 (running for 00:09:01.37)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:33 (running for 00:09:06.39)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:18:38,822\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:38 (running for 00:09:11.39)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:43 (running for 00:09:16.41)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:48 (running for 00:09:21.41)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:53 (running for 00:09:26.42)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:18:58 (running for 00:09:31.43)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:03 (running for 00:09:36.44)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:08 (running for 00:09:41.44)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:13 (running for 00:09:46.46)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:18 (running for 00:09:51.46)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:23 (running for 00:09:56.48)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:28 (running for 00:10:01.49)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:33 (running for 00:10:06.50)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:19:38,931\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:38 (running for 00:10:11.50)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:43 (running for 00:10:16.52)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:48 (running for 00:10:21.52)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:53 (running for 00:10:26.54)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:19:58 (running for 00:10:31.54)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:03 (running for 00:10:36.56)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:08 (running for 00:10:41.56)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:14 (running for 00:10:46.57)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:19 (running for 00:10:51.58)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:24 (running for 00:10:56.59)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:29 (running for 00:11:01.60)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:34 (running for 00:11:06.62)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:20:39,051\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:39 (running for 00:11:11.63)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:44 (running for 00:11:16.64)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:49 (running for 00:11:21.65)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:54 (running for 00:11:26.66)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:20:59 (running for 00:11:31.67)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:04 (running for 00:11:36.69)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:09 (running for 00:11:41.69)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:14 (running for 00:11:46.71)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:19 (running for 00:11:51.71)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:24 (running for 00:11:56.73)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:29 (running for 00:12:01.73)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:34 (running for 00:12:06.75)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 15:21:39,186\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 3.0 cpu and 0 gpu per trial, but the cluster only has 2.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:39 (running for 00:12:11.76)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:44 (running for 00:12:16.77)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:49 (running for 00:12:21.78)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:54 (running for 00:12:26.79)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:21:59 (running for 00:12:31.79)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:04 (running for 00:12:36.82)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:09 (running for 00:12:41.82)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:14 (running for 00:12:46.84)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:19 (running for 00:12:51.84)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:24 (running for 00:12:56.86)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-08-22 15:22:29 (running for 00:13:01.86)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              3000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "<tr><td>PPO_MultiAgentArena_6a368_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.5   </td><td style=\"text-align: right;\">              4000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Another example of using Ray Tune for the Parameters \n",
        "Now we will use DQN\n",
        "and Ray Tune runner to train the algo\n",
        "\n",
        "https://www.codeproject.com/Articles/5271939/Cartpole-The-Hello-World-of-Reinforcement-Learning"
      ],
      "metadata": {
        "id": "kpzRZxWpPBVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune\n",
        "from ray.rllib.agents.dqn import DQNTrainer\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.progress_reporter import JupyterNotebookReporter\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init(\n",
        "    ignore_reinit_error=True\n",
        ")\n",
        "\n",
        "ENV = 'CartPole-v0'\n",
        "TARGET_REWARD = 195  #it stops when this reward has been achieved\n",
        "TRAINER = DQNTrainer\n",
        "\n",
        "# TRAINING PARAMETERS\n",
        "#Stopping criteria\n",
        "stop_dict ={\"training_iteration\": 3,\n",
        "            \"timesteps_total\"   : 5,\n",
        "            \"episode_reward_mean\": TARGET_REWARD # stop as soon as we \"solve\" the environment            \n",
        "            }  \n",
        "\n",
        "# Parameters for the trainer function - if we use PPO, we can add the Net layers here as above\n",
        "config_dict = { \"env\": ENV,\n",
        "                \"num_workers\": 0,  # run in a single process\n",
        "                \"num_gpus\": 0\n",
        "                }\n",
        "\n",
        "# Runner\n",
        "analysis =  tune.run(\n",
        "              TRAINER,\n",
        "              stop  = stop_dict,\n",
        "              config= config_dict,\n",
        "              progress_reporter=JupyterNotebookReporter(overwrite=False),\n",
        "              verbose=2 #can be changed\n",
        "          )"
      ],
      "metadata": {
        "id": "DVL7jQlkPE5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyse the training results"
      ],
      "metadata": {
        "id": "TBHL9dGjPLU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = analysis.dataframe()\n",
        "df"
      ],
      "metadata": {
        "id": "nGaqjyd6PMNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why did we use 6 CPUs in the tune run above (3 CPUs per trial)?\n",
        "\n",
        "PPO - by default - uses 2 \"rollout\" workers (`num_workers=2`). These are Ray Actors that have their own environment copy(ies) and step through those in parallel. On top of these two \"rollout\" workers, every Trainer in RLlib always also has a \"local\" worker, which - in case of PPO - handles the learning updates. This gives us 3 workers (2 rollout + 1 local learner), which require 3 CPUs."
      ],
      "metadata": {
        "id": "pC_kjrMuGjrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Parallelization\n",
        "\n",
        "<hr />\n",
        "\n",
        "Using the `tune_config` that we have built so far, let's run another `tune.run()`, but apply the following changes to our setup this time:\n",
        "- Setup only 1 learning rate under the \"lr\" config key. Chose the (seemingly) best value from the run in the previous cell (the one that yielded the highest avg. reward).\n",
        "- Setup only 1 train batch size under the \"train_batch_size\" config key. Chose the (seemingly) best value from the run in the previous cell (the one that yielded the highest avg. reward).\n",
        "- Set `num_workers` to 5, which will allow us to run more environment \"rollouts\" in parallel and to collect training batches more quickly.\n",
        "- Set the `num_envs_per_worker` config parameter to 5. This will clone our env on each rollout worker, and thus parallelize action computing forward passes through our neural networks.\n",
        "\n",
        "Other than that, use the exact same args as in our `tune.run()` call in the previous cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "p7OIQ_W8Gp10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### This might not be needed, check the resources utilization in the dashboard ####\n",
        "\n",
        "#Initialize service and pass the number of resources available\n",
        "ray.init(num_cpus = 1,\n",
        "         num_gpus = 0,\n",
        "         ignore_reinit_error = True)"
      ],
      "metadata": {
        "id": "bIx-qN0kNfIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run for longer this time (100 iterations) and try to reach 40.0 reward (sum of both agents).\n",
        "stop = {\n",
        "    \"training_iteration\": 180,  # we have the 15min break now to run this many iterations\n",
        "    \"episode_reward_mean\": 60.0,  # sum of both agents' rewards. Probably won't reach it, but we should try nevertheless :)\n",
        "}\n",
        "\n",
        "# tune_config.update({\n",
        "# ???\n",
        "# })\n",
        "\n",
        "\n",
        "\n",
        "tune_config[\"lr\"] = 0.0001\n",
        "tune_config[\"train_batch_size\"] = 4000\n",
        "tune_config[\"num_envs_per_worker\"] = 5\n",
        "tune_config[\"num_workers\"] = 5\n",
        "\n",
        "analysis = tune.run(\"PPO\", config=tune_config, stop=stop, checkpoint_at_end=True, checkpoint_freq=5)"
      ],
      "metadata": {
        "id": "rKk1qQYcGwbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional parameters we can pass to the config dict\n",
        "\n",
        "If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger sgd_minibatch_size, a smaller num_sgd_iter, or a larger num_workers.\n",
        "\n",
        "```\n",
        "num_sgd_iter -  is the number of epochs of SGD (stochastic gradient descent, i.e., passes through the data) that will be used to optimize the PPO surrogate objective at each iteration of PPO, for each minibatch (\"chunk\") of training data. Using minibatches is more efficient than training with one record at a time.\n",
        "\n",
        "sgd_minibatch_size  - is the SGD minibatch size (batches of data) that will be used to optimize the PPO surrogate objective.\n",
        "\n",
        "num_cpus_per_worker  - when set to 0 prevents Ray from pinning a CPU core to \n",
        "each worker, which means we could run out of workers in a constrained environment like a laptop or a cloud VM.\n",
        "```"
      ],
      "metadata": {
        "id": "VBEiuRulNsuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = ppo.DEFAULT_CONFIG.copy()              # PPO's default configuration. \n",
        "config[\"log_level\"] = \"WARN\"                    # Suppress too many messages, but try \"INFO\" to see what can be printed.\n",
        "\n",
        "# Other settings we might adjust:\n",
        "config[\"num_workers\"] = 1                       # Use > 1 for using more CPU cores, including over a cluster\n",
        "config[\"num_sgd_iter\"] = 10                     # Number of SGD (stochastic gradient descent) iterations per training minibatch.\n",
        "                                                # I.e., for each minibatch of data, do this many passes over it to train. \n",
        "config[\"sgd_minibatch_size\"] = 250              # The amount of data records per minibatch\n",
        "config[\"model\"][\"fcnet_hiddens\"] = [100, 50]    # Neural network with two hidden layers, the list contains the number of weights on each layer\n",
        "config[\"num_cpus_per_worker\"] = 0               # This avoids running out of resources in the notebook environment when this cell is re-executed"
      ],
      "metadata": {
        "id": "etI28tuYNxTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ppo.PPOTrainer(config, env=SELECT_ENV)\n",
        "\n",
        "results = []\n",
        "episode_data = []\n",
        "episode_json = []\n",
        "\n",
        "for n in range(N_ITER):\n",
        "    result = agent.train()\n",
        "    results.append(result)\n",
        "    \n",
        "    episode = {'n': n, \n",
        "               'episode_reward_min': result['episode_reward_min'], \n",
        "               'episode_reward_mean': result['episode_reward_mean'], \n",
        "               'episode_reward_max': result['episode_reward_max'],  \n",
        "               'episode_len_mean': result['episode_len_mean']}\n",
        "    \n",
        "    episode_data.append(episode)\n",
        "    episode_json.append(json.dumps(episode))\n",
        "    file_name = agent.save(CHECKPOINT_ROOT)\n",
        "    \n",
        "    print(f'{n:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}. Checkpoint saved to {file_name}')"
      ],
      "metadata": {
        "id": "dZyLxSlnN3Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How do we extract any checkpoint from a trial of a tune.run?"
      ],
      "metadata": {
        "id": "9bL0ZI2YHEeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore from a file\n",
        "\n",
        "# Bring the model config\n",
        "trained_config = config.copy()\n",
        "\n",
        "# Load trained model\n",
        "test_agent = ppo.PPOTrainer(trained_config, SELECT_ENV) #initialize object\n",
        "test_agent.restore(file_name)  #above we have defined: file_name = agent.save(CHECKPOINT_ROOT)"
      ],
      "metadata": {
        "id": "yzjoFShHN_jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The previous tune.run (the one we did before the exercise) returned an Analysis object, from which we can access any checkpoint\n",
        "# (given we set checkpoint_freq or checkpoint_at_end to reasonable values) like so:\n",
        "print(analysis)\n",
        "# Get all trials (we only have one).\n",
        "trials = analysis.trials\n",
        "# Assuming, the first trial was the best, we'd like to extract this trial's best checkpoint \"\":\n",
        "best_checkpoint = analysis.get_best_checkpoint(trial=trials[0], metric=\"episode_reward_mean\", mode=\"max\")\n",
        "print(f\"Found best checkpoint for trial #2: {best_checkpoint}\")\n",
        "\n",
        "# Undo the grid-search config, which RLlib doesn't understand.\n",
        "rllib_config = tune_config.copy()\n",
        "rllib_config[\"lr\"] = 0.00005\n",
        "rllib_config[\"train_batch_size\"] = 4000\n",
        "\n",
        "# Restore a RLlib Trainer from the checkpoint.\n",
        "new_trainer = PPOTrainer(config=rllib_config)\n",
        "new_trainer.restore(best_checkpoint)\n",
        "new_trainer"
      ],
      "metadata": {
        "id": "FBqBytfhHE6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = Output()\n",
        "display.display(out)\n",
        "\n",
        "with out:\n",
        "    obs = env.reset()\n",
        "    while True:\n",
        "        a1 = new_trainer.compute_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
        "        a2 = new_trainer.compute_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
        "        actions = {\"agent1\": a1, \"agent2\": a2}\n",
        "        obs, rewards, dones, _ = env.step(actions)\n",
        "\n",
        "        out.clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(0.07)\n",
        "\n",
        "        if dones[\"agent1\"] is True:\n",
        "            break"
      ],
      "metadata": {
        "id": "_GJ-YjGAHLf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's talk about customization options"
      ],
      "metadata": {
        "id": "mzxDOAVKHP_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Dive: How do we customize RLlib's RL loop?\n",
        "\n",
        "RLlib offers a callbacks API that allows you to add custom behavior to\n",
        "all major events during the environment sampling- and learning process.\n",
        "\n",
        "**Our problem:** So far, we can only see standard stats, such as rewards, episode lengths, etc..\n",
        "This does not give us enough insights sometimes into important questions, such as: How many times\n",
        "have both agents collided? or How many times has agent1 discovered a new field?\n",
        "\n",
        "In the following cell, we will create custom callback \"hooks\" that will allow us to\n",
        "add these stats to the returned metrics dict, and which will therefore be displayed in tensorboard!\n",
        "\n",
        "For that we will override RLlib's DefaultCallbacks class and implement the\n",
        "`on_episode_start`, `on_episode_step`, and `on_episode_end` methods therein:\n"
      ],
      "metadata": {
        "id": "3xzjmtr-HT8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Override the DefaultCallbacks with your own and implement any methods (hooks)\n",
        "# that you need.\n",
        "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
        "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
        "\n",
        "\n",
        "class MyCallbacks(DefaultCallbacks):\n",
        "    def on_episode_start(self,\n",
        "                         *,\n",
        "                         worker,\n",
        "                         base_env,\n",
        "                         policies,\n",
        "                         episode: MultiAgentEpisode,\n",
        "                         env_index,\n",
        "                         **kwargs):\n",
        "        # We will use the `MultiAgentEpisode` object being passed into\n",
        "        # all episode-related callbacks. It comes with a user_data property (dict),\n",
        "        # which we can write arbitrary data into.\n",
        "\n",
        "        # At the end of an episode, we'll transfer that data into the `hist_data`, and `custom_metrics`\n",
        "        # properties to make sure our custom data is displayed in TensorBoard.\n",
        "\n",
        "        # The episode is starting:\n",
        "        # Set per-episode object to capture, which states (observations)\n",
        "        # have been visited by agent1.\n",
        "        episode.user_data[\"new_fields_discovered\"] = 0\n",
        "        # Set per-episode agent2-blocks counter (how many times has agent2 blocked agent1?).\n",
        "        episode.user_data[\"num_collisions\"] = 0\n",
        "\n",
        "    def on_episode_step(self,\n",
        "                        *,\n",
        "                        worker,\n",
        "                        base_env,\n",
        "                        episode: MultiAgentEpisode,\n",
        "                        env_index,\n",
        "                        **kwargs):\n",
        "        # Get both rewards.\n",
        "        ag1_r = episode.prev_reward_for(\"agent1\")\n",
        "        ag2_r = episode.prev_reward_for(\"agent2\")\n",
        "\n",
        "        # Agent1 discovered a new field.\n",
        "        if ag1_r == 1.0:\n",
        "            episode.user_data[\"new_fields_discovered\"] += 1\n",
        "        # Collision.\n",
        "        elif ag2_r == 1.0:\n",
        "            episode.user_data[\"num_collisions\"] += 1\n",
        "\n",
        "    def on_episode_end(self,\n",
        "                       *,\n",
        "                       worker,\n",
        "                       base_env,\n",
        "                       policies,\n",
        "                       episode: MultiAgentEpisode,\n",
        "                       env_index,\n",
        "                       **kwargs):\n",
        "        # Episode is done:\n",
        "        # Write scalar values (sum over rewards) to `custom_metrics` and\n",
        "        # time-series data (rewards per time step) to `hist_data`.\n",
        "        # Both will be visible then in TensorBoard.\n",
        "        episode.custom_metrics[\"new_fields_discovered\"] = episode.user_data[\"new_fields_discovered\"]\n",
        "        episode.custom_metrics[\"num_collisions\"] = episode.user_data[\"num_collisions\"]\n"
      ],
      "metadata": {
        "id": "vZWJOGibHTQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution Exercise #3"
      ],
      "metadata": {
        "id": "FJHzfrdzIeNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import ray\n",
        "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
        "from ray import tune\n",
        "\n",
        "\n",
        "class MyCallback(DefaultCallbacks):\n",
        "    def on_episode_start(self, *, worker, base_env,\n",
        "                         policies, episode,\n",
        "                         env_index, **kwargs):\n",
        "        # Set per-episode object to capture, which states (observations)\n",
        "        # have been visited by agent1.\n",
        "        episode.user_data[\"ground_covered\"] = set()\n",
        "        # Set per-episode agent2-blocks counter (how many times has agent2 blocked agent1?).\n",
        "        episode.user_data[\"num_blocks\"] = 0\n",
        "\n",
        "    def on_episode_step(self, *, worker, base_env,\n",
        "                        episode, env_index, **kwargs):\n",
        "        # Add agent1's observation to our set of unique observations.\n",
        "        ag1_obs = episode.last_raw_obs_for(\"agent1\")\n",
        "        episode.user_data[\"ground_covered\"].add(ag1_obs)\n",
        "        # If agent2's reward > 0.0, it means she has blocked agent1.\n",
        "        ag2_r = episode.prev_reward_for(\"agent2\")\n",
        "        if ag2_r > 0.0:\n",
        "            episode.user_data[\"num_blocks\"] += 1\n",
        "\n",
        "    def on_episode_end(self, *, worker, base_env,\n",
        "                       policies, episode,\n",
        "                       env_index, **kwargs):\n",
        "        # Reset everything.\n",
        "        episode.user_data[\"ground_covered\"] = set()\n",
        "        episode.user_data[\"num_blocks\"] = 0\n",
        "\n",
        "\n",
        "\n",
        "ray.init()\n",
        "\n",
        "stop = {\"training_iteration\": 10}\n",
        "# Specify env and custom callbacks in our config (leave everything else\n",
        "# as-is (defaults)).\n",
        "config = {\n",
        "    \"env\": MultiAgentArena,\n",
        "    \"callbacks\": MyCallback,\n",
        "}\n",
        "\n",
        "# Run for a few iterations.\n",
        "tune.run(\"PPO\", stop=stop, config=config)\n",
        "\n",
        "# Check tensorboard."
      ],
      "metadata": {
        "id": "2FydvqVRIZ2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up our config to point to our new custom callbacks class:\n",
        "config = {\n",
        "    \"env\": MultiAgentArena,\n",
        "    \"callbacks\": MyCallbacks,  # by default, this would point to `rllib.agents.callbacks.DefaultCallbacks`, which does nothing.\n",
        "    \"num_workers\": 5,  # we know now: this speeds up things!\n",
        "}\n",
        "\n",
        "tune.run(\n",
        "    \"PPO\",\n",
        "    config=config,\n",
        "    stop={\"training_iteration\": 20},\n",
        "    checkpoint_at_end=True,\n",
        "    # If you'd like to restore the tune run from an existing checkpoint file, you can do the following:\n",
        "    #restore=\"/Users/sven/ray_results/PPO/PPO_MultiAgentArena_fd451_00000_0_2021-05-25_15-13-26/checkpoint_000010/checkpoint-10\",\n",
        ")"
      ],
      "metadata": {
        "id": "jJ6VExcdHbZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's check tensorboard for the new custom metrics!\n",
        "\n",
        "1. Head over to the Anyscale project view and click on the \"TensorBoard\" button\n",
        "\n",
        "See images here:\n",
        "\n",
        "https://github.com/sven1977/rllib_tutorials/blob/865d77eacb8cb8025abe372d97c47f70aa1d035b/ray_summit_2021/tutorial_notebook.ipynb\n",
        "\n",
        "Alternatively - if you ran this locally on your own machine:\n",
        "\n",
        "1. Head over to ~/ray_results/PPO/PPO_MultiAgentArena_[some key]_00000_0_[date]_[time]/\n",
        "1. In that directory, you should see a `event.out....` file.\n",
        "1. Run `tensorboard --logdir .` and head to https://localhost:6006\n",
        "\n"
      ],
      "metadata": {
        "id": "V-iiQARPHijq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Dive: Writing custom Models in tf or torch."
      ],
      "metadata": {
        "id": "Ih9qvGK5H23l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
        "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
        "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
        "\n",
        "tf1, tf, tf_version = try_import_tf()\n",
        "torch, nn = try_import_torch()\n",
        "\n",
        "\n",
        "# Custom Neural Network Models.\n",
        "class MyKerasModel(TFModelV2):\n",
        "    \"\"\"Custom model for policy gradient algorithms.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
        "                 name):\n",
        "        \"\"\"Build a simple [16, 16]-MLP (+ value branch).\"\"\"\n",
        "        super(MyKerasModel, self).__init__(obs_space, action_space,\n",
        "                                           num_outputs, model_config, name)\n",
        "        \n",
        "        # Keras Input layer.\n",
        "        self.inputs = tf.keras.layers.Input(\n",
        "            shape=obs_space.shape, name=\"observations\")\n",
        "\n",
        "        # Hidden layer (shared by action logits outputs and value output).\n",
        "        layer_1 = tf.keras.layers.Dense(\n",
        "            16,\n",
        "            name=\"layer1\",\n",
        "            activation=tf.nn.relu)(self.inputs)\n",
        "        \n",
        "        # Action logits output.\n",
        "        logits = tf.keras.layers.Dense(\n",
        "            num_outputs,\n",
        "            name=\"out\",\n",
        "            activation=None)(layer_1)\n",
        "\n",
        "        # \"Value\"-branch (single node output).\n",
        "        # Used by several RLlib algorithms (e.g. PPO) to calculate an observation's value.\n",
        "        value_out = tf.keras.layers.Dense(\n",
        "            1,\n",
        "            name=\"value\",\n",
        "            activation=None)(layer_1)\n",
        "\n",
        "        # The actual Keras model:\n",
        "        self.base_model = tf.keras.Model(self.inputs,\n",
        "                                         [logits, value_out])\n",
        "\n",
        "    def forward(self, input_dict, state, seq_lens):\n",
        "        \"\"\"Custom-define your forard pass logic here.\"\"\"\n",
        "        # Pass inputs through our 2 layers and calculate the \"value\"\n",
        "        # of the observation and store it for when `value_function` is called.\n",
        "        logits, self.cur_value = self.base_model(input_dict[\"obs\"])\n",
        "        return logits, state\n",
        "\n",
        "    def value_function(self):\n",
        "        \"\"\"Implement the value branch forward pass logic here:\n",
        "        \n",
        "        We will just return the already calculated `self.cur_value`.\n",
        "        \"\"\"\n",
        "        assert self.cur_value is not None, \"Must call `forward()` first!\"\n",
        "        return tf.reshape(self.cur_value, [-1])\n",
        "\n",
        "\n",
        "class MyTorchModel(TorchModelV2, nn.Module):\n",
        "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
        "                 name):\n",
        "        \"\"\"Build a simple [16, 16]-MLP (+ value branch).\"\"\"\n",
        "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
        "                              model_config, name)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.device = torch.device(\"cuda\"\n",
        "                                   if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Hidden layer (shared by action logits outputs and value output).\n",
        "        self.layer_1 = nn.Linear(obs_space.shape[0], 16).to(self.device)\n",
        "\n",
        "        # Action logits output.\n",
        "        self.layer_out = nn.Linear(16, num_outputs).to(self.device)\n",
        "\n",
        "        # \"Value\"-branch (single node output).\n",
        "        # Used by several RLlib algorithms (e.g. PPO) to calculate an observation's value.\n",
        "        self.value_branch = nn.Linear(16, 1).to(self.device)\n",
        "        self.cur_value = None\n",
        "\n",
        "    def forward(self, input_dict, state, seq_lens):\n",
        "        \"\"\"Custom-define your forard pass logic here.\"\"\"\n",
        "        # Pass inputs through our 2 layers.\n",
        "        layer_1_out = self.layer_1(input_dict[\"obs\"])\n",
        "        logits = self.layer_out(layer_1_out)\n",
        "\n",
        "        # Calculate the \"value\" of the observation and store it for\n",
        "        # when `value_function` is called.\n",
        "        self.cur_value = self.value_branch(layer_1_out).squeeze(1)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def value_function(self):\n",
        "        \"\"\"Implement the value branch forward pass logic here:\n",
        "        \n",
        "        We will just return the already calculated `self.cur_value`.\n",
        "        \"\"\"\n",
        "        assert self.cur_value is not None, \"Must call `forward()` first!\"\n",
        "        return self.cur_value"
      ],
      "metadata": {
        "id": "ZwgJ4TrzHp8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do a quick test on the custom model classes.\n",
        "test_model_tf = MyKerasModel(\n",
        "    obs_space=gym.spaces.Box(-1.0, 1.0, (2, )),\n",
        "    action_space=None,\n",
        "    num_outputs=2,\n",
        "    model_config={},\n",
        "    name=\"MyModel\",\n",
        ")\n",
        "\n",
        "print(\"TF-output={}\".format(test_model_tf({\"obs\": np.array([[0.5, 0.5]])})))\n",
        "\n",
        "# For PyTorch, you can do:\n",
        "#test_model_torch = MyTorchModel(\n",
        "#    obs_space=gym.spaces.Box(-1.0, 1.0, (2, )),\n",
        "#    action_space=None,\n",
        "#    num_outputs=2,\n",
        "#    model_config={},\n",
        "#    name=\"MyModel\",\n",
        "#)\n",
        "#print(\"Torch-output={}\".format(test_model_torch({\"obs\": torch.from_numpy(np.array([[0.5, 0.5]], dtype=np.float32))})))\n"
      ],
      "metadata": {
        "id": "5BtD8-A9IBBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up our custom model and re-run the experiment.\n",
        "config.update({\n",
        "    \"model\": {\n",
        "        \"custom_model\": MyKerasModel,  # for torch users: \"custom_model\": MyTorchModel\n",
        "        \"custom_model_config\": {\n",
        "            #\"layers\": [128, 128],\n",
        "        },\n",
        "    },\n",
        "})\n",
        "\n",
        "tune.run(\n",
        "    \"PPO\",\n",
        "    config=config,  # for torch users: config=dict(config, **{\"framework\": \"torch\"}),\n",
        "    stop={\n",
        "        \"training_iteration\": 5,\n",
        "    },\n",
        ")\n"
      ],
      "metadata": {
        "id": "6yBFFqhkIEaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Rollout\n",
        "\n",
        "Once we have trained a policy, we deploy it in the environment.\n",
        "\n",
        "A 'Rollout' is the application of the trained policy to the environment. This is, for a given state, the policy function will output the best action to take.\n",
        "\n",
        "****************************************************************************\n",
        "\n",
        "WARNING: The rllib rollout command discussed next won't work in a cloud environment, because it attempts to pop up a window.\n",
        "\n",
        "\n",
        "https://docs.ray.io/en/latest/rllib-concepts.html#policy-evaluation\n",
        "\n",
        "***************************************************************************"
      ],
      "metadata": {
        "id": "yngSlQUvOPZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of rollout: \n",
        "\n",
        "Reuse the trained policy to act in an environment\n",
        "The line: `test_agent.compute_action(state)` uses the trained policy to pick an action given the state.\n",
        "\n",
        "The reward received should match the training reward"
      ],
      "metadata": {
        "id": "4waZQI4qOSjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env   = gym.make(SELECT_ENV)\n",
        "state = env.reset()\n",
        "done  = False\n",
        "cumulative_reward = 0\n",
        "\n",
        "while not done:\n",
        "  action = test_agent.compute_single_action(state) #gets the next action given a state\n",
        "  state, reward, done, _ = env.step(action)\n",
        "  cumulative_reward += reward\n",
        "\n",
        "print(cumulative_reward)  "
      ],
      "metadata": {
        "id": "2Ufy0mP-OTQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard results\n",
        "\n",
        "Note: one can also use WandB"
      ],
      "metadata": {
        "id": "lsIyy1T2Ok0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From command line:\n",
        "#tensorboard - logdir=$HOME/ray_results/"
      ],
      "metadata": {
        "id": "ELAUYYQUOogt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shut down the service"
      ],
      "metadata": {
        "id": "VFHbw2_1OsLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.shutdown()"
      ],
      "metadata": {
        "id": "ug6x6atROtWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Dive: A closer look at RLlib's components\n",
        "\n",
        "We already took a quick look inside an RLlib Trainer object and extracted its Policy(ies) and the Policy's model (neural network). \n",
        "\n",
        "Here is a much more detailed overview of what's inside a Trainer object.\n",
        "\n",
        "At the core is the so-called `WorkerSet` sitting under `Trainer.workers`. A WorkerSet is a group of `RolloutWorker` (`rllib.evaluation.rollout_worker.py`) objects that always consists of a \"local worker\" (`Trainer.workers.local_worker()`) and 'n' \"remote workers\" (`Trainer.workers.remote_workers()`).\n",
        "\n",
        "See image here:\n",
        "\n",
        "https://github.com/sven1977/rllib_tutorials/blob/865d77eacb8cb8025abe372d97c47f70aa1d035b/ray_summit_2021/tutorial_notebook.ipynb"
      ],
      "metadata": {
        "id": "9ZTttgLxH89J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling RLlib\n",
        "\n",
        "Scaling RLlib works by parallelizing the \"jobs\" that the remote `RolloutWorkers` do. In a vanilla RL algorithm, like PPO, DQN, and many others, the `@ray.remote` labeled RolloutWorkers in the figure above are responsible for interacting with one or more environments and thereby collecting experiences. Observations are produced by the environment, actions are then computed by the Policy(ies) copy located on the remote worker and sent to the environment in order to produce yet another observation. This cycle is repeated endlessly and only sometimes interrupted to send experience batches (\"train batches\") of a certain size to the \"local worker\". There these batches are used to call `Policy.learn_on_batch()`, which performs a loss calculation, followed by a model weights update, and a subsequent weights broadcast back to all the remote workers."
      ],
      "metadata": {
        "id": "EUBB5K2sI4UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here are a couple of links that you may find useful.\n",
        "\n",
        "- The <a href=\"https://github.com/sven1977/rllib_tutorials.git\">github repo of this tutorial</a>.\n",
        "- <a href=\"https://docs.ray.io/en/master/rllib.html\">RLlib's documentation main page</a>.\n",
        "- <a href=\"http://discuss.ray.io\">Our discourse forum</a> to ask questions on Ray and its libraries.\n",
        "- Our <a href=\"https://forms.gle/9TSdDYUgxYs8SA9e8\">Slack channel</a> for interacting with other Ray RLlib users.\n",
        "- The <a href=\"https://github.com/ray-project/ray/blob/master/rllib/examples/\">RLlib examples scripts folder</a> with tons of examples on how to do different stuff with RLlib.\n",
        "- A <a href=\"https://medium.com/distributed-computing-with-ray/reinforcement-learning-with-rllib-in-the-unity-game-engine-1a98080a7c0d\">blog post on training with RLlib inside a Unity3D environment</a>.\n"
      ],
      "metadata": {
        "id": "4Et_H6ccJEYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ESBAtS-QJFFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Rise Camp Fall 2021 RLlib Tutorial",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e94ca5f6a1e7489cb809a7feec2e7dae": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4b2d58ec16994b8b8b66ae272b26b670",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "____________\n",
                  "|.         |\n",
                  "|..        |\n",
                  "|..        |\n",
                  "|...       |\n",
                  "|...       |\n",
                  "|...       |\n",
                  "|....      |\n",
                  "| ..1...   |\n",
                  "| .2....   |\n",
                  "| ..  .    |\n",
                  "‾‾‾‾‾‾‾‾‾‾‾‾\n",
                  "\n",
                  "R1=-2.0\n",
                  "R2=-10.0\n",
                  "\n"
                ]
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "4b2d58ec16994b8b8b66ae272b26b670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e348ce501c54e0ab7b7bc59c582726a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_251a8af5c17344b08b3c119fdb0a2109",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "____________\n",
                  "|..   .....|\n",
                  "| .........|\n",
                  "| .........|\n",
                  "|  ...... .|\n",
                  "|  .... .1.|\n",
                  "|   .   ...|\n",
                  "|   .   .  |\n",
                  "|   . ...  |\n",
                  "|   ..2.   |\n",
                  "|   ..     |\n",
                  "‾‾‾‾‾‾‾‾‾‾‾‾\n",
                  "\n",
                  "R1= 30.5\n",
                  "R2=-8.9\n",
                  "\n"
                ]
              }
            ],
            "tabbable": null,
            "tooltip": null
          }
        },
        "251a8af5c17344b08b3c119fdb0a2109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}