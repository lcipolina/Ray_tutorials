{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDT5vQb3/h6nkCYTeLFMQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/Ray_tutorials/blob/main/WandB_RLLIB_2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvE4ovepRa9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0ae1fd-ac60-4a04-ef09-4e52944069fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ray, version 2.4.0\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ray[rllib] --quiet #ray, version 2.4.0\n",
        "! ray --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "import wandb\n",
        "from ray.air.integrations.wandb import WandbLoggerCallback"
      ],
      "metadata": {
        "id": "CUi4jQ97jbdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP8N7at6k28j",
        "outputId": "d668731f-6fd7-453a-a344-71f895fa4851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlcipolina\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import ray\n",
        "#from ray.rllib.env import MultiAgentEnv #RLLIB 2.2\n",
        "from ray import air, tune\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "\n",
        "#from ray.rllib.env.multi_agent_env import MultiAgentEnv #new RLLIB 2.3\n",
        "#from ray.rllib.policy.policy import PolicySpec #For multi-policy mapping"
      ],
      "metadata": {
        "id": "B0gEOpEri308"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Gym on RLLIB 2.3\n",
        "!pip install gymnasium --quiet\n",
        "import gymnasium as gym\n",
        "#from gym.spaces import MultiDiscrete\n",
        "#from gym.spaces import Tuple, Box, MultiDiscrete, Discrete"
      ],
      "metadata": {
        "id": "fyh6016jmV44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure experiments and train"
      ],
      "metadata": {
        "id": "vSDivxmHjGQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.rllib.examples.env.two_step_game import TwoStepGame"
      ],
      "metadata": {
        "id": "PD4efhByWSF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/ray-project/ray/blob/17596b03d189f2e6d642fb5690aefb01faec90d1/rllib/examples/centralized_critic_2.py\n",
        "\n",
        "#Simplified version\n",
        "\n",
        "config = PPOConfig()\\\n",
        "        .environment(TwoStepGame)\\\n",
        "        .framework(\"torch\")\\\n",
        "        .rollouts(batch_mode=\"complete_episodes\", num_rollout_workers=0)\n",
        "      "
      ],
      "metadata": {
        "id": "SGyBjtzJLR8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [WandbLoggerCallback(\n",
        "\tproject='WANDB_PROJECT',\n",
        "        log_config=True)]"
      ],
      "metadata": {
        "id": "cq-nskvWSwQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ray.is_initialized(): ray.shutdown()\n",
        "ray.init(local_mode=True,include_dashboard=False, ignore_reinit_error=True) \n",
        "\n",
        "\n",
        "stop = {\n",
        "        \"training_iteration\": 1,\n",
        "        \"timesteps_total\": 1\n",
        "    }\n",
        "\n",
        "tuner = tune.Tuner(\n",
        "        \"PPO\",\n",
        "        param_space=config.to_dict(),\n",
        "        run_config=air.RunConfig(  stop=stop, verbose=1, callbacks=callbacks\n",
        "                                 ),\n",
        "       )\n",
        "\n",
        "results = tuner.fit()\n",
        "\n",
        "# Get the best result based on a particular metric.\n",
        "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\") #TODO: en realidad, tengo que max por separado\n",
        "result_df = best_result.metrics_dataframe\n",
        "print(\"BEST RESULTS:\")\n",
        "print(result_df[[\"training_iteration\",'episode_reward_mean','episode_len_mean']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jztVLPvNPsde",
        "outputId": "f1fb6015-99ca-4ab2-fc15-00a4579fdc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-02 16:49:31,620\tINFO worker.py:1625 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-02 16:49:34,614\tINFO wandb.py:315 -- Already logged into W&B.\n",
            ":task_name:bundle_reservation_check_func\n",
            ":actor_name:PPO\n",
            "2023-05-02 16:49:34,759\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\r<IPython.core.display.HTML object>\n",
            ":task_name:bundle_reservation_check_func\n",
            ":actor_name:PPO\n",
            ":actor_name:PPO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ":actor_name:PPO\n",
            "2023-05-02 16:50:24,137\tWARNING util.py:244 -- The `start_trial` operation took 49.492 s, which may be a performance bottleneck.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRaySystemError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\u001b[0m in \u001b[0;36m_wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_ExecutorEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPG_READY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_pg_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_ExecutorEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_RUNNING_TRIAL_TIMEOUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\u001b[0m in \u001b[0;36m_on_pg_ready\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0mtrial_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_start_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial_started\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnext_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\u001b[0m in \u001b[0;36m_start_trial\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m   1417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                     self._callbacks.on_trial_start(\n\u001b[0m\u001b[1;32m   1419\u001b[0m                         \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/callback.py\u001b[0m in \u001b[0;36mon_trial_start\u001b[0;34m(self, **info)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/logger/logger.py\u001b[0m in \u001b[0;36mon_trial_start\u001b[0;34m(self, iteration, trials, trial, **info)\u001b[0m\n\u001b[1;32m    134\u001b[0m     ):\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_trial_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/integrations/wandb.py\u001b[0m in \u001b[0;36mlog_trial_start\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_logging_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwandb_init_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/integrations/wandb.py\u001b[0m in \u001b[0;36m_start_logging_actor\u001b[0;34m(self, trial, exclude_results, **wandb_init_kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         self._trial_queues[trial] = Queue(\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mactor_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_cpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_force_on_current_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/util/queue.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, maxsize, actor_options)\u001b[0m\n\u001b[1;32m     57\u001b[0m         self.actor = (\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_QueueActor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mactor_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/actor.py\u001b[0m in \u001b[0;36mremote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mactor_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mupdated_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\u001b[0m in \u001b[0;36m_invocation_actor_class_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"_ray_trace_ctx\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/actor.py\u001b[0m in \u001b[0;36m_remote\u001b[0;34m(self, args, kwargs, **actor_options)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         actor_id = worker.core_worker.create_actor(\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.create_actor\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.create_actor\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRaySystemError\u001b[0m: System error: Async actor is currently not supported for the local mode",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTuneError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_restored\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36m_fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    620\u001b[0m         }\n\u001b[0;32m--> 621\u001b[0;31m         analysis = run(\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[1;32m    903\u001b[0m             ):\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_and_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\u001b[0m in \u001b[0;36m_wait_and_handle_event\u001b[0;34m(self, next_trial)\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\", line 1373, in _wait_and_handle_event\n    self._on_pg_ready(next_trial)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\", line 1427, in _on_pg_ready\n    trial_started = _start_trial(next_trial)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/execution/trial_runner.py\", line 1418, in _start_trial\n    self._callbacks.on_trial_start(\n  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/callback.py\", line 349, in on_trial_start\n    callback.on_trial_start(**info)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/logger/logger.py\", line 135, in on_trial_start\n    self.log_trial_start(trial)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/air/integrations/wandb.py\", line 636, in log_trial_start\n    self._start_logging_actor(trial, exclude_results, **wandb_init_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/air/integrations/wandb.py\", line 652, in _start_logging_actor\n    self._trial_queues[trial] = Queue(\n  File \"/usr/local/lib/python3.10/dist-packages/ray/util/queue.py\", line 58, in __init__\n    ray.remote(_QueueActor).options(**actor_options).remote(self.maxsize)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/actor.py\", line 639, in remote\n    return actor_cls._remote(args=args, kwargs=kwargs, **updated_options)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 381, in _invocation_actor_class_remote_span\n    return method(self, args, kwargs, *_args, **_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/ray/actor.py\", line 968, in _remote\n    actor_id = worker.core_worker.create_actor(\n  File \"python/ray/_raylet.pyx\", line 2076, in ray._raylet.CoreWorker.create_actor\n  File \"python/ray/_raylet.pyx\", line 2119, in ray._raylet.CoreWorker.create_actor\n  File \"python/ray/_raylet.pyx\", line 211, in ray._raylet.check_status\nray.exceptions.RaySystemError: System error: Async actor is currently not supported for the local mode\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-951233971cb8>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Get the best result based on a particular metric.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTuneError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 raise TuneError(\n\u001b[0m\u001b[1;32m    370\u001b[0m                     _TUNER_FAILED_MSG.format(\n\u001b[1;32m    371\u001b[0m                         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_experiment_checkpoint_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"/root/ray_results/PPO\", trainable=...)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other things that didn't work"
      ],
      "metadata": {
        "id": "aUz9zLsSXnr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!from ray.rllib.env.wrappers.multi_agent_env_compatibility import MultiAgentEnvCompatibility #Don't know how this works. Aparently is passed to the config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVpTf8zBnRMy",
        "outputId": "151f8805-b06d-4048-8c1b-9f531ebd439e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from: can't read /var/mail/ray.rllib.env.wrappers.multi_agent_env_compatibility\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple MARL custom Environment\n",
        "\n",
        "'''Simple Multi-agent environment to test things\n",
        "'''\n",
        "\n",
        "\n",
        "class TurnEnv(MultiAgentEnv):\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        super().__init__()\n",
        "        self.num_agents              = 2\n",
        "        self.t                       = 0\n",
        "        self.agent_lst               = list(range(self.num_agents))\n",
        "        self._agent_ids              = set(self.agent_lst)\n",
        "\n",
        "        # Now RLLIB needs both 'terminated' and 'truncated' to reset the environment\n",
        "        self.terminateds             = {agent: False for agent in self.agent_lst} #new RLLIB 2.3\n",
        "        self.terminateds['__all__']  = False\n",
        "        self.truncateds              = {agent: False for agent in self.agent_lst} #new RLLIB 2.3\n",
        "        self.truncateds['__all__']   = False\n",
        "        self.info_dict               = {}\n",
        "\n",
        "        self.observation_space       = Discrete(self.num_agents)\n",
        "        self.action_space            = self.observation_space\n",
        "\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        agentID = 0\n",
        "        self.info_dict = {agentID:\n",
        "                     {\"done\": self.terminateds[\"__all__\"]}\n",
        "                     } #new RLLIB 2.3  \n",
        "        return {agentID: self.observation_space.sample()},self.info_dict # {agent:obs}, {agent:info}\n",
        "\n",
        "\n",
        "    def step(self, action_dict):\n",
        "        \n",
        "        self.t +=1\n",
        "        \n",
        "        # TEST\n",
        "        #if not action_dict:\n",
        "        #   print(\"EMPTY ACTION DICT!!!\")\n",
        "        #   print('self.t =', self.t)\n",
        "       \n",
        "        if self.t == 10: \n",
        "           self.truncateds             = {agent: True for agent in self.agent_lst}\n",
        "           self.truncateds['__all__']  = True\n",
        "        \n",
        "        \n",
        "        agentID = 1\n",
        "        return {agentID:self.observation_space.sample()},\\\n",
        "               {agentID:1},\\\n",
        "               self.terminateds, \\\n",
        "               self.truncateds,\\\n",
        "               self.info_dict\n",
        "               #obs, rewards, terminateds, truncateds, infos\n"
      ],
      "metadata": {
        "id": "KgMyTkDsjDHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.spaces import Dict, Discrete, Tuple, MultiDiscrete\n",
        "from ray.tune import register_env\n",
        "from ray.tune.registry import get_trainable_cls"
      ],
      "metadata": {
        "id": "IRrraxxLEMhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/ray-project/ray/blob/master/rllib/examples/env/two_step_game.py\n",
        "\n",
        "from ray.rllib.env.multi_agent_env import MultiAgentEnv, ENV_STATE\n",
        "\n",
        "class A_TwoStepGame(MultiAgentEnv):\n",
        "    action_space = Discrete(2)\n",
        "\n",
        "    def __init__(self, env_config):\n",
        "        super().__init__()\n",
        "        self.action_space = Discrete(2)\n",
        "        self.state = None\n",
        "        self.agent_1 = 0\n",
        "        self.agent_2 = 1\n",
        "        self._skip_env_checking = True\n",
        "        # MADDPG emits action logits instead of actual discrete actions\n",
        "        self.actions_are_logits = env_config.get(\"actions_are_logits\", False)\n",
        "        self.one_hot_state_encoding = env_config.get(\"one_hot_state_encoding\", False)\n",
        "        self.with_state = env_config.get(\"separate_state_space\", False)\n",
        "        self._agent_ids = {0, 1}\n",
        "        if not self.one_hot_state_encoding:\n",
        "            self.observation_space = Discrete(6)\n",
        "            self.with_state = False\n",
        "        else:\n",
        "            # Each agent gets the full state (one-hot encoding of which of the\n",
        "            # three states are active) as input with the receiving agent's\n",
        "            # ID (1 or 2) concatenated onto the end.\n",
        "            if self.with_state:\n",
        "                self.observation_space = Dict(\n",
        "                    {\n",
        "                        \"obs\": MultiDiscrete([2, 2, 2, 3]),\n",
        "                        ENV_STATE: MultiDiscrete([2, 2, 2]),\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                self.observation_space = MultiDiscrete([2, 2, 2, 3])\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "        self.state = np.array([1, 0, 0])\n",
        "        return self._obs(), {}\n",
        "\n",
        "    def step(self, action_dict):\n",
        "        if self.actions_are_logits:\n",
        "            action_dict = {\n",
        "                k: np.random.choice([0, 1], p=v) for k, v in action_dict.items()\n",
        "            }\n",
        "\n",
        "        state_index = np.flatnonzero(self.state)\n",
        "        if state_index == 0:\n",
        "            action = action_dict[self.agent_1]\n",
        "            assert action in [0, 1], action\n",
        "            if action == 0:\n",
        "                self.state = np.array([0, 1, 0])\n",
        "            else:\n",
        "                self.state = np.array([0, 0, 1])\n",
        "            global_rew = 0\n",
        "            terminated = False\n",
        "        elif state_index == 1:\n",
        "            global_rew = 7\n",
        "            terminated = True\n",
        "        else:\n",
        "            if action_dict[self.agent_1] == 0 and action_dict[self.agent_2] == 0:\n",
        "                global_rew = 0\n",
        "            elif action_dict[self.agent_1] == 1 and action_dict[self.agent_2] == 1:\n",
        "                global_rew = 8\n",
        "            else:\n",
        "                global_rew = 1\n",
        "            terminated = True\n",
        "\n",
        "        rewards = {self.agent_1: global_rew / 2.0, self.agent_2: global_rew / 2.0}\n",
        "        obs = self._obs()\n",
        "        terminateds = {\"__all__\": terminated}\n",
        "        truncateds = {\"__all__\": False}\n",
        "        infos = {\n",
        "            self.agent_1: {\"done\": terminateds[\"__all__\"]},\n",
        "            self.agent_2: {\"done\": terminateds[\"__all__\"]},\n",
        "        }\n",
        "        return obs, rewards, terminateds, truncateds, infos\n",
        "\n",
        "    def _obs(self):\n",
        "        if self.with_state:\n",
        "            return {\n",
        "                self.agent_1: {\"obs\": self.agent_1_obs(), ENV_STATE: self.state},\n",
        "                self.agent_2: {\"obs\": self.agent_2_obs(), ENV_STATE: self.state},\n",
        "            }\n",
        "        else:\n",
        "            return {self.agent_1: self.agent_1_obs(), self.agent_2: self.agent_2_obs()}\n",
        "\n",
        "    def agent_1_obs(self):\n",
        "        if self.one_hot_state_encoding:\n",
        "            return np.concatenate([self.state, [1]])\n",
        "        else:\n",
        "            return np.flatnonzero(self.state)[0]\n",
        "\n",
        "    def agent_2_obs(self):\n",
        "        if self.one_hot_state_encoding:\n",
        "            return np.concatenate([self.state, [2]])\n",
        "        else:\n",
        "            return np.flatnonzero(self.state)[0] + 3\n"
      ],
      "metadata": {
        "id": "D_wx4ivjBvWY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}